{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Nadja_Part1_LinearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sTIC0lkE4hR"
      },
      "source": [
        "# Simple Linear versus Ridge Regression by Nadja Fejzic\r\n",
        "# February 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtF0OxzlPtsx"
      },
      "source": [
        "# Prone to overfitting - really good at predicting the training data but may not be good at generalizing - might be off with another dataset\r\n",
        "# Cannot be used when the relation between independent and dependent variable is nonlinear"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoQA8bZpE4he"
      },
      "source": [
        "## Step 1:  Getting, understanding, and preprocessing the dataset\n",
        "\n",
        "We first import the standard libaries and some libraries that will help us scale the data and perform some \"feature engineering\" by transforming the data into $\\Phi_2({\\bf x})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsplynqaE4hg"
      },
      "source": [
        "# Importing libraries\n",
        "import numpy as np\n",
        "import sklearn\n",
        "# Importing the boston dataset from sklearn\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import preprocessing\n",
        "# Spliting data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Modeling the relationship between a scalar respose (dependent variable) and one or more explainatory variables (independent variables)\n",
        "import sklearn.linear_model \n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWcW0PzJE4hh"
      },
      "source": [
        "###  Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPaPFCkFE4hi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8add081-f2a7-42c9-ce85-616ae5e01e8d"
      },
      "source": [
        "# Loading the dataset \n",
        "boston_data = load_boston()\n",
        "print(\"This is the example of linear regression using Boston house prices dataset\\n\")\n",
        "print(boston_data.DESCR)\n",
        "print(boston_data.keys())\n",
        "\n",
        "print(\"\\n------------This is the actual data-------------\\n\")\n",
        "print(boston_data)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the example of linear regression using Boston house prices dataset\n",
            "\n",
            ".. _boston_dataset:\n",
            "\n",
            "Boston house prices dataset\n",
            "---------------------------\n",
            "\n",
            "**Data Set Characteristics:**  \n",
            "\n",
            "    :Number of Instances: 506 \n",
            "\n",
            "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
            "\n",
            "    :Attribute Information (in order):\n",
            "        - CRIM     per capita crime rate by town\n",
            "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
            "        - INDUS    proportion of non-retail business acres per town\n",
            "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
            "        - NOX      nitric oxides concentration (parts per 10 million)\n",
            "        - RM       average number of rooms per dwelling\n",
            "        - AGE      proportion of owner-occupied units built prior to 1940\n",
            "        - DIS      weighted distances to five Boston employment centres\n",
            "        - RAD      index of accessibility to radial highways\n",
            "        - TAX      full-value property-tax rate per $10,000\n",
            "        - PTRATIO  pupil-teacher ratio by town\n",
            "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
            "        - LSTAT    % lower status of the population\n",
            "        - MEDV     Median value of owner-occupied homes in $1000's\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
            "\n",
            "This is a copy of UCI ML housing dataset.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
            "\n",
            "\n",
            "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
            "\n",
            "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
            "prices and the demand for clean air', J. Environ. Economics & Management,\n",
            "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
            "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
            "pages 244-261 of the latter.\n",
            "\n",
            "The Boston house-price data has been used in many machine learning papers that address regression\n",
            "problems.   \n",
            "     \n",
            ".. topic:: References\n",
            "\n",
            "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
            "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
            "\n",
            "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n",
            "\n",
            "------------This is the actual data-------------\n",
            "\n",
            "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
            "        4.9800e+00],\n",
            "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
            "        9.1400e+00],\n",
            "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
            "        4.0300e+00],\n",
            "       ...,\n",
            "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
            "        5.6400e+00],\n",
            "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
            "        6.4800e+00],\n",
            "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
            "        7.8800e+00]]), 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
            "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
            "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
            "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
            "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
            "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
            "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
            "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
            "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
            "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
            "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
            "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
            "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
            "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
            "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
            "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
            "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
            "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
            "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
            "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
            "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
            "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
            "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
            "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
            "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
            "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
            "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
            "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
            "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
            "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
            "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
            "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
            "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
            "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
            "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
            "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
            "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
            "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
            "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
            "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
            "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
            "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
            "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
            "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
            "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
            "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]), 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
            "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'), 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\", 'filename': '/usr/local/lib/python3.6/dist-packages/sklearn/datasets/data/boston_house_prices.csv'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKKb9nFwE4hi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59e38e2-e604-470e-e52f-450dc54a1901"
      },
      "source": [
        "#  Creating X and Y variables - X holding the .data and Y holding .target \n",
        "X = boston_data.data #independent variables\n",
        "y = boston_data.target #dependent variable - price of houses\n",
        "feature_names = boston_data.feature_names\n",
        "\n",
        "# Checking the dimensions of X and Y arrays (data arrays) \n",
        "print(\"The dimension of X: \", X.ndim)\n",
        "print(\"The initial dimension of Y: \", y.ndim) \n",
        "# We see that Y is one dimensional array\n",
        "# Reshaping Y to be a rank 2 matrix using y.reshape() since we have no row-column concept\n",
        "y = y.reshape(-1,1)\n",
        "# now we see it created one column to store the data in \n",
        "print(\"The dimension of Y after reshaping: \",y.ndim, \"\\n\")\n",
        "\n",
        "# Exploring the data\n",
        "# Observing the number of features and the number of labels -- the number of columns\n",
        "print(\"The number of features is: \", X.shape[1])\n",
        "\n",
        "# Printing out the features -- columns\n",
        "print(\"The features: \", feature_names, \"\\n\")\n",
        "\n",
        "# The number of examples -- the number of rows\n",
        "print(\"The number of examples in our dataset: \", X.shape[0], \"\\n\")\n",
        "\n",
        "# Observing the first 2 rows of the data\n",
        "print(\"The first two rows of the data:\\n\", X[0:2], \"\\n\")\n",
        "print(\"\\nData:\\n\", X, \"\\n\")\n",
        "print(\"\\nTarget:\\n\", y, \"\\n\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dimension of X:  2\n",
            "The initial dimension of Y:  1\n",
            "The dimension of Y after reshaping:  2 \n",
            "\n",
            "The number of features is:  13\n",
            "The features:  ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
            " 'B' 'LSTAT'] \n",
            "\n",
            "The number of examples in our dataset:  506 \n",
            "\n",
            "The first two rows of the data:\n",
            " [[6.3200e-03 1.8000e+01 2.3100e+00 0.0000e+00 5.3800e-01 6.5750e+00\n",
            "  6.5200e+01 4.0900e+00 1.0000e+00 2.9600e+02 1.5300e+01 3.9690e+02\n",
            "  4.9800e+00]\n",
            " [2.7310e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 6.4210e+00\n",
            "  7.8900e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9690e+02\n",
            "  9.1400e+00]] \n",
            "\n",
            "\n",
            "Data:\n",
            " [[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
            " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
            " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
            " ...\n",
            " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
            " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
            " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]] \n",
            "\n",
            "\n",
            "Target:\n",
            " [[24. ]\n",
            " [21.6]\n",
            " [34.7]\n",
            " [33.4]\n",
            " [36.2]\n",
            " [28.7]\n",
            " [22.9]\n",
            " [27.1]\n",
            " [16.5]\n",
            " [18.9]\n",
            " [15. ]\n",
            " [18.9]\n",
            " [21.7]\n",
            " [20.4]\n",
            " [18.2]\n",
            " [19.9]\n",
            " [23.1]\n",
            " [17.5]\n",
            " [20.2]\n",
            " [18.2]\n",
            " [13.6]\n",
            " [19.6]\n",
            " [15.2]\n",
            " [14.5]\n",
            " [15.6]\n",
            " [13.9]\n",
            " [16.6]\n",
            " [14.8]\n",
            " [18.4]\n",
            " [21. ]\n",
            " [12.7]\n",
            " [14.5]\n",
            " [13.2]\n",
            " [13.1]\n",
            " [13.5]\n",
            " [18.9]\n",
            " [20. ]\n",
            " [21. ]\n",
            " [24.7]\n",
            " [30.8]\n",
            " [34.9]\n",
            " [26.6]\n",
            " [25.3]\n",
            " [24.7]\n",
            " [21.2]\n",
            " [19.3]\n",
            " [20. ]\n",
            " [16.6]\n",
            " [14.4]\n",
            " [19.4]\n",
            " [19.7]\n",
            " [20.5]\n",
            " [25. ]\n",
            " [23.4]\n",
            " [18.9]\n",
            " [35.4]\n",
            " [24.7]\n",
            " [31.6]\n",
            " [23.3]\n",
            " [19.6]\n",
            " [18.7]\n",
            " [16. ]\n",
            " [22.2]\n",
            " [25. ]\n",
            " [33. ]\n",
            " [23.5]\n",
            " [19.4]\n",
            " [22. ]\n",
            " [17.4]\n",
            " [20.9]\n",
            " [24.2]\n",
            " [21.7]\n",
            " [22.8]\n",
            " [23.4]\n",
            " [24.1]\n",
            " [21.4]\n",
            " [20. ]\n",
            " [20.8]\n",
            " [21.2]\n",
            " [20.3]\n",
            " [28. ]\n",
            " [23.9]\n",
            " [24.8]\n",
            " [22.9]\n",
            " [23.9]\n",
            " [26.6]\n",
            " [22.5]\n",
            " [22.2]\n",
            " [23.6]\n",
            " [28.7]\n",
            " [22.6]\n",
            " [22. ]\n",
            " [22.9]\n",
            " [25. ]\n",
            " [20.6]\n",
            " [28.4]\n",
            " [21.4]\n",
            " [38.7]\n",
            " [43.8]\n",
            " [33.2]\n",
            " [27.5]\n",
            " [26.5]\n",
            " [18.6]\n",
            " [19.3]\n",
            " [20.1]\n",
            " [19.5]\n",
            " [19.5]\n",
            " [20.4]\n",
            " [19.8]\n",
            " [19.4]\n",
            " [21.7]\n",
            " [22.8]\n",
            " [18.8]\n",
            " [18.7]\n",
            " [18.5]\n",
            " [18.3]\n",
            " [21.2]\n",
            " [19.2]\n",
            " [20.4]\n",
            " [19.3]\n",
            " [22. ]\n",
            " [20.3]\n",
            " [20.5]\n",
            " [17.3]\n",
            " [18.8]\n",
            " [21.4]\n",
            " [15.7]\n",
            " [16.2]\n",
            " [18. ]\n",
            " [14.3]\n",
            " [19.2]\n",
            " [19.6]\n",
            " [23. ]\n",
            " [18.4]\n",
            " [15.6]\n",
            " [18.1]\n",
            " [17.4]\n",
            " [17.1]\n",
            " [13.3]\n",
            " [17.8]\n",
            " [14. ]\n",
            " [14.4]\n",
            " [13.4]\n",
            " [15.6]\n",
            " [11.8]\n",
            " [13.8]\n",
            " [15.6]\n",
            " [14.6]\n",
            " [17.8]\n",
            " [15.4]\n",
            " [21.5]\n",
            " [19.6]\n",
            " [15.3]\n",
            " [19.4]\n",
            " [17. ]\n",
            " [15.6]\n",
            " [13.1]\n",
            " [41.3]\n",
            " [24.3]\n",
            " [23.3]\n",
            " [27. ]\n",
            " [50. ]\n",
            " [50. ]\n",
            " [50. ]\n",
            " [22.7]\n",
            " [25. ]\n",
            " [50. ]\n",
            " [23.8]\n",
            " [23.8]\n",
            " [22.3]\n",
            " [17.4]\n",
            " [19.1]\n",
            " [23.1]\n",
            " [23.6]\n",
            " [22.6]\n",
            " [29.4]\n",
            " [23.2]\n",
            " [24.6]\n",
            " [29.9]\n",
            " [37.2]\n",
            " [39.8]\n",
            " [36.2]\n",
            " [37.9]\n",
            " [32.5]\n",
            " [26.4]\n",
            " [29.6]\n",
            " [50. ]\n",
            " [32. ]\n",
            " [29.8]\n",
            " [34.9]\n",
            " [37. ]\n",
            " [30.5]\n",
            " [36.4]\n",
            " [31.1]\n",
            " [29.1]\n",
            " [50. ]\n",
            " [33.3]\n",
            " [30.3]\n",
            " [34.6]\n",
            " [34.9]\n",
            " [32.9]\n",
            " [24.1]\n",
            " [42.3]\n",
            " [48.5]\n",
            " [50. ]\n",
            " [22.6]\n",
            " [24.4]\n",
            " [22.5]\n",
            " [24.4]\n",
            " [20. ]\n",
            " [21.7]\n",
            " [19.3]\n",
            " [22.4]\n",
            " [28.1]\n",
            " [23.7]\n",
            " [25. ]\n",
            " [23.3]\n",
            " [28.7]\n",
            " [21.5]\n",
            " [23. ]\n",
            " [26.7]\n",
            " [21.7]\n",
            " [27.5]\n",
            " [30.1]\n",
            " [44.8]\n",
            " [50. ]\n",
            " [37.6]\n",
            " [31.6]\n",
            " [46.7]\n",
            " [31.5]\n",
            " [24.3]\n",
            " [31.7]\n",
            " [41.7]\n",
            " [48.3]\n",
            " [29. ]\n",
            " [24. ]\n",
            " [25.1]\n",
            " [31.5]\n",
            " [23.7]\n",
            " [23.3]\n",
            " [22. ]\n",
            " [20.1]\n",
            " [22.2]\n",
            " [23.7]\n",
            " [17.6]\n",
            " [18.5]\n",
            " [24.3]\n",
            " [20.5]\n",
            " [24.5]\n",
            " [26.2]\n",
            " [24.4]\n",
            " [24.8]\n",
            " [29.6]\n",
            " [42.8]\n",
            " [21.9]\n",
            " [20.9]\n",
            " [44. ]\n",
            " [50. ]\n",
            " [36. ]\n",
            " [30.1]\n",
            " [33.8]\n",
            " [43.1]\n",
            " [48.8]\n",
            " [31. ]\n",
            " [36.5]\n",
            " [22.8]\n",
            " [30.7]\n",
            " [50. ]\n",
            " [43.5]\n",
            " [20.7]\n",
            " [21.1]\n",
            " [25.2]\n",
            " [24.4]\n",
            " [35.2]\n",
            " [32.4]\n",
            " [32. ]\n",
            " [33.2]\n",
            " [33.1]\n",
            " [29.1]\n",
            " [35.1]\n",
            " [45.4]\n",
            " [35.4]\n",
            " [46. ]\n",
            " [50. ]\n",
            " [32.2]\n",
            " [22. ]\n",
            " [20.1]\n",
            " [23.2]\n",
            " [22.3]\n",
            " [24.8]\n",
            " [28.5]\n",
            " [37.3]\n",
            " [27.9]\n",
            " [23.9]\n",
            " [21.7]\n",
            " [28.6]\n",
            " [27.1]\n",
            " [20.3]\n",
            " [22.5]\n",
            " [29. ]\n",
            " [24.8]\n",
            " [22. ]\n",
            " [26.4]\n",
            " [33.1]\n",
            " [36.1]\n",
            " [28.4]\n",
            " [33.4]\n",
            " [28.2]\n",
            " [22.8]\n",
            " [20.3]\n",
            " [16.1]\n",
            " [22.1]\n",
            " [19.4]\n",
            " [21.6]\n",
            " [23.8]\n",
            " [16.2]\n",
            " [17.8]\n",
            " [19.8]\n",
            " [23.1]\n",
            " [21. ]\n",
            " [23.8]\n",
            " [23.1]\n",
            " [20.4]\n",
            " [18.5]\n",
            " [25. ]\n",
            " [24.6]\n",
            " [23. ]\n",
            " [22.2]\n",
            " [19.3]\n",
            " [22.6]\n",
            " [19.8]\n",
            " [17.1]\n",
            " [19.4]\n",
            " [22.2]\n",
            " [20.7]\n",
            " [21.1]\n",
            " [19.5]\n",
            " [18.5]\n",
            " [20.6]\n",
            " [19. ]\n",
            " [18.7]\n",
            " [32.7]\n",
            " [16.5]\n",
            " [23.9]\n",
            " [31.2]\n",
            " [17.5]\n",
            " [17.2]\n",
            " [23.1]\n",
            " [24.5]\n",
            " [26.6]\n",
            " [22.9]\n",
            " [24.1]\n",
            " [18.6]\n",
            " [30.1]\n",
            " [18.2]\n",
            " [20.6]\n",
            " [17.8]\n",
            " [21.7]\n",
            " [22.7]\n",
            " [22.6]\n",
            " [25. ]\n",
            " [19.9]\n",
            " [20.8]\n",
            " [16.8]\n",
            " [21.9]\n",
            " [27.5]\n",
            " [21.9]\n",
            " [23.1]\n",
            " [50. ]\n",
            " [50. ]\n",
            " [50. ]\n",
            " [50. ]\n",
            " [50. ]\n",
            " [13.8]\n",
            " [13.8]\n",
            " [15. ]\n",
            " [13.9]\n",
            " [13.3]\n",
            " [13.1]\n",
            " [10.2]\n",
            " [10.4]\n",
            " [10.9]\n",
            " [11.3]\n",
            " [12.3]\n",
            " [ 8.8]\n",
            " [ 7.2]\n",
            " [10.5]\n",
            " [ 7.4]\n",
            " [10.2]\n",
            " [11.5]\n",
            " [15.1]\n",
            " [23.2]\n",
            " [ 9.7]\n",
            " [13.8]\n",
            " [12.7]\n",
            " [13.1]\n",
            " [12.5]\n",
            " [ 8.5]\n",
            " [ 5. ]\n",
            " [ 6.3]\n",
            " [ 5.6]\n",
            " [ 7.2]\n",
            " [12.1]\n",
            " [ 8.3]\n",
            " [ 8.5]\n",
            " [ 5. ]\n",
            " [11.9]\n",
            " [27.9]\n",
            " [17.2]\n",
            " [27.5]\n",
            " [15. ]\n",
            " [17.2]\n",
            " [17.9]\n",
            " [16.3]\n",
            " [ 7. ]\n",
            " [ 7.2]\n",
            " [ 7.5]\n",
            " [10.4]\n",
            " [ 8.8]\n",
            " [ 8.4]\n",
            " [16.7]\n",
            " [14.2]\n",
            " [20.8]\n",
            " [13.4]\n",
            " [11.7]\n",
            " [ 8.3]\n",
            " [10.2]\n",
            " [10.9]\n",
            " [11. ]\n",
            " [ 9.5]\n",
            " [14.5]\n",
            " [14.1]\n",
            " [16.1]\n",
            " [14.3]\n",
            " [11.7]\n",
            " [13.4]\n",
            " [ 9.6]\n",
            " [ 8.7]\n",
            " [ 8.4]\n",
            " [12.8]\n",
            " [10.5]\n",
            " [17.1]\n",
            " [18.4]\n",
            " [15.4]\n",
            " [10.8]\n",
            " [11.8]\n",
            " [14.9]\n",
            " [12.6]\n",
            " [14.1]\n",
            " [13. ]\n",
            " [13.4]\n",
            " [15.2]\n",
            " [16.1]\n",
            " [17.8]\n",
            " [14.9]\n",
            " [14.1]\n",
            " [12.7]\n",
            " [13.5]\n",
            " [14.9]\n",
            " [20. ]\n",
            " [16.4]\n",
            " [17.7]\n",
            " [19.5]\n",
            " [20.2]\n",
            " [21.4]\n",
            " [19.9]\n",
            " [19. ]\n",
            " [19.1]\n",
            " [19.1]\n",
            " [20.1]\n",
            " [19.9]\n",
            " [19.6]\n",
            " [23.2]\n",
            " [29.8]\n",
            " [13.8]\n",
            " [13.3]\n",
            " [16.7]\n",
            " [12. ]\n",
            " [14.6]\n",
            " [21.4]\n",
            " [23. ]\n",
            " [23.7]\n",
            " [25. ]\n",
            " [21.8]\n",
            " [20.6]\n",
            " [21.2]\n",
            " [19.1]\n",
            " [20.6]\n",
            " [15.2]\n",
            " [ 7. ]\n",
            " [ 8.1]\n",
            " [13.6]\n",
            " [20.1]\n",
            " [21.8]\n",
            " [24.5]\n",
            " [23.1]\n",
            " [19.7]\n",
            " [18.3]\n",
            " [21.2]\n",
            " [17.5]\n",
            " [16.8]\n",
            " [22.4]\n",
            " [20.6]\n",
            " [23.9]\n",
            " [22. ]\n",
            " [11.9]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ho05jY1E4hj"
      },
      "source": [
        "We will also create polynomial feeatures for the dataset to test linear and ridge regression on data with d = 1 and data with d = 2. Feel free to increase the # of degress and see what effect it has on the training and test error. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLoxIdPcE4hk"
      },
      "source": [
        "# Createing a PolynomialFeatures object with degree = 2\n",
        "# Transforming X and saving it into X_2 using poly.fit_transform(X)\n",
        "# Simply copying Y into Y_2 \n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_2 = poly.fit_transform(X)\n",
        "y_2 = y \n",
        "\n",
        "#poly = PolynomialFeatures(degree=3)\n",
        "#X_3 = poly.fit_transform(X)\n",
        "#y_3 = y"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-22ngZVtE4hk",
        "outputId": "adccd684-6c30-4c31-ef6a-5f2fb3de623f"
      },
      "source": [
        "# The shape of X_2 and Y_2 - should be (506, 105) and (506, 1) respectively\n",
        "\n",
        "print(\"The shape of X_2 -- \", X_2.shape)\n",
        "print(\"The shape of Y_2 -- \", y_2.shape)\n",
        "\n",
        "#print(X_2)\n",
        "#print(y_2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of X_2 --  (506, 105)\n",
            "The shape of Y_2 --  (506, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHpFZNid_sa7"
      },
      "source": [
        "SIMPLE linear regression \r\n",
        "\r\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQAAAAA3CAYAAADjepTHAAAgAElEQVR4Ae29B3QV1df3TxJAsYu9YaGIgKAIqNgLKAiCIFUQpDdp0nvvvUuX3kR6b0JCQgudENJ7T25yb25N+LzrzM3JPRkmCb/nedbz/7/v4q41OWfv/d3l7DNzZubMmUmJu3fvIjb509OSL0ojmaorMYXpGGFV3v3Y19vW08XZk/j78aXaEnqqTlEyPVb1aVSXeCmTtOpD9a3ijLCSp+JUW3q5kUzlGfnWy4vzpcertF5XLyuO1uvraVVf1FVaYCVdlEza1GOM6MKwqi8VI+v6UsYl+Ua+jDACr8dKnrQl6RJ6oJ7WKxTmUOKM5JInSxWr8kRdpWWQEq8vjbAqz8ietGEkU3WNfKs6RliVp2JVn0b14nxJuWpf2ilMpscWRRvJVJ6oq7T0KWMoSiaxKsbInmpLxUp9KTeii5Lpfelp1V5RMulDjzGiC8OqvlSMrOtLYVv9GfkywggdPVby9PYeDABKRgpLpoSoSTXCqjwVq+ob1QVP1ZW0yjOyp9pSsVJfyoujjXRVnpFvvbw4X3q8Sut19bLiaL2+nlb1RV2lBVbSRcmkTT3GiC4Mq/pSMbKuL2Vckm/kywgj8Hqs5Elbkn4wACgZKSyZEqIm1Qir8lSsqm9UFzxVV9Iqz8ieakvFSn0pL4420lV5Rr718uJ86fEqrdfVy4qj9fp6WtUXdZUWWEkXJZM29RgjujCs6kvFyLq+lHFJvpEvI4zA67GSJ21J+sEAoGSksGRKiJpUI6zKU7GqvlFd8FRdSas8I3uqLRUr9aW8ONpIV+UZ+dbLi/Olx6u0XlcvK47W6+tpVV/UVVpgJV2UTNrUY4zowrCqLxUj6/pSxiX5Rr6MMAKvx0qetCXpBwOAkpHCkikhalKNsCpPxar6RnXBU3UlrfKM7Km2VKzUl/LiaCNdlWfkWy8vzpcer9J6Xb2sOFqvr6dVfVFXaYGVdFEyaVOPMaILw6q+VIys60sZl+Qb+TLCCLweK3nSlqQfDABKRgpLpoSoSTXCqjwVq+ob1QVP1ZW0yjOyp9pSsVJfyoujjXRVnpFvvbw4X3q8Sut19bLiaL2+nlb1RV2lBVbSRcmkTT3GiC4Mq/pSMbKuL2Vckm/kywgj8Hqs5Elbkn4wACgZKSyZEqIm1Qir8lSsqm9UFzxVV9Iqz8ieakvFSn0pL4420lV5Rr718uJ86fEqrdfVy4qj9fp6WtUXdZUWWEkXJZM29RgjujCs6kvFyLq+lHFJvpEvI4zA67GSJ21J+sEAoGSksGRKiJpUI6zKU7GqvlFd8PS6uTkuXC4nLqcDp7Y5cTqdGs9NC76gXThdOeTk5t5jQ/rS29fTqm8pU3n/nbbcrz2BEz+Pr7uCICfHicNqxWG348rNJVdjF3w8lqear6+n77ctHt9aINy9m4vohxyRY6cTh8O95feDy4nD6cDhdOJ0if5yaf2QKwaZAm3xRKTGIrh62oO8V1YgvmLs67FGvgTmwQCgZFzfGUa05MlSqgta5elpfQeoWI9M223IyXFhyzZjNqWTmZ6GSWwZ6ZgEbUp319NFmYHJlEWmxY7VIXY+z4FhbF9GW3DnMsKqPFFXaU+8bntFySRWxRjZk5G5ZWIwEwefE6vZREpsLKnJKWTZnThy7o1F6kpfero431KuxnU3N5ccpx2HNQtzViYZGSbS002kpZtIzzCRYTKRkZlOuklsGWSYMjFlWbCKQfnuXXKLOUBljNK3pNVSL1PjEzg9LXmyNNLX238wACgZuZ+ESYwspbqgVZ6elp2i4mU9X3Y3l7s5NszpcVzxO8WJfXvx9fXD/+wZAk7u4ej+7fzzzw6OnzzJhYsXOX/qMP6njnP6aji34jKx2F35JtVY8u3nS/9/PADk5pDrspJtiic2NJBzp46wc9NOTv57nqgMC2bXXcQZtrCfUbtVXlH94pHdJcdpIyMmiLCLR/H1Pc3hMwGcDfDjzL9H2b1nF3sOHeaE/3n8L/pz7vxpDh7y4+CR64TFZ2ARg0cxB6iMX41N8mSpl3nicyP0tOBKnaJkqv0HA4DMhpI8yZLJVGnJk6WRTPCK6wBD/VwXufZkYm6fYcnYIQzs2ImpMxewYP4MFoxoy+/tG9CocSMGjRrPyr/WsXxcP+aOHsjYNYfZfC6apCy7uGrWfkb2ZawyPkkbYVWeqKv0/ehL2xKr6hvZk/i7uU5c1iQSQ/04sW0WU4f0ovmPXRg9dTUXolNJdeSSIxsplZRS9XO/vqVOflx3c3BkpxNyagt7Zv/O+EkTGTB9IQuXzGD6hH40b/4jrTr3ZPi8FSxevYiVyybRp890uvbZyLELEaS7chBDcb69YuJTxAWqMi7J1NvT0wIndYqSqfYeDAAyG0ryJEsmU6UlT5ZGMsErrgOM9MUlr9McScTVIyydOpERA4azdNUG1i6fxeKB9Wn1XV0qvvcD3YdMZ9uuf9g6ewjLJw9m3F9H2BgQQ1Lm/wsDgIscWypJ4f6c3jGNUT3bUb1qYzr0mcOZ0CSS/zcGgFwbdnMcV45sYeP0IcyYu4BpK9eycd1MJg1vT/VqFan7fVOGL17P2h0b2bFlMcOHLKLvgK2cvhiJyflgAJDHRYEDwWinV3nFHTT5RvMqqq7RQWdkT9owkhnZE6dU7X7U5cCWlUV2ZiZ2uxNnjpiQ8lyK6u3paRmf6l/WpSzX5cCaGkJcsC8nT/ly8GQgN26Hcu30TvbPaEfPdr9Ro8FkJi8/TlhkGGHndnPxxA52nr3J6ZB0MqwOXA4bNrOJzIw00tI8W2pqqkKnk5ZmwpJtw+5yYbdlYzVnkpHuxgusxKebzGQKnDPHPbGVF7SaK7Uu26Jvm4oxyo3Eu+/97WSnRRB5aTuLJo/gveqtaddzPmdCkkj5XxgA7uZkYTNHc+1CAHt3HsLX/wo3b18jJHAHa+b25/0a7/JD685sOHGRy+HhhIXd5Oihc+zeeZHIqFQcYt+4j5OAUa5kHoxk+rzpaVWnKJn0ITAPrgBkNgq5Argr7kmdFswJ4Vzft5Ozf//N9TuxxGc5cLhEN7t/+oTraYESPPlT61J2N8eJPSsRU3I40XHJRCebyTRnEHpmF38P+IkBHX7nx/47WHc4BIvVgi0lnNS4YG7HphKVlk22zUJyWCBXDq5l++oFzJszm9mz3dusWbPy67NnL2HBok0cORNIaHwCodfOEnBoK2v+XKRhBFbDz1vAkk372H76NnfiTTjzJrdkvEW1RcokVm2vUW4k3i3LxWlJIj30KGsXTOODmr/SvudCfEOS/1cGAHKtOO2pxMTEceNWDEnJJsxp0cRf3sTaGX/wQc3mtO46g39vxZKUbSfblk1cTDIRoYlkZVrJzZuMNWqnmgeZG9l2fWmEVXlF2S9KJv0IzIMBQGZDd4BqZ/7cHHIc2WQlBHPn1C42DPqdxf0Gse/0Na5Fp5KSGEdSfDRRkZFERERoW2RkJGKLiBBbFFFR8SSnmrDY7GSbTWSlJZIQF61hJDYyKorouCTiUzPJNJux27Ox2R3YHDbs2QkE7l7NtHof0bdtbwYuOcPhK0nao79cpxWXPRuLzYlNPKaymQgP2MneaR3p1+Iz6tasQtXKFalYsSIVKlSgQoVKVKhYlRrv16PeD72ZseIf/G7dxv/AOtZP/Z1ffvyC2u9XpfLbb1Oteg0++rIejXtOYNCfxzh5OYT0zAzSzdlkiSuNHPcVgUifulMWRqsYo51TdoOUubKTyYw4zvpFM6j1QQfa91yEnzIACJyYpbeaUkhLjCEmOiov7xEFciv6ITIyloTEVLKybWRnm7GkJ5OcEKf1m7uv8nRi4ohNNmltdDrt2Gx2zBYbDoeDrKQ73DowgwVDelDnk1F0HbyHa5HpWFy5Wi7sor9EXlw5BeZh1HYXlhvZdn1ppKvyRF2lVftFyaQfgXkwAMhs6HZk96WoBUtqOIH/rGXj8H5M6DmA6RMXc/pKCNeuXuDcziVsWDCeMSOHM2zoUIYOHcqwYcO0bejQYQwdNp5RYxawcecJroRFEnT5DAF7VrNk9mSGDx+ejx0+cjQT5q9l8e6LnA9JwuJ0P9LLdZmxmW5zaN0sWtZ4h9/a92HevutcjMpyP/ITVxTirJwrZsZzcDmzSQ715/zOGczo9R2N33+ecmUfoqSPDz4+Pnh7P0rJUq9Q4+Of6TFiKVuOnCc4Lp6Qq76c2DyHcT3qUa/2Kzz/zOO8XaMWzboMYPiCLaw9cJ6Asye4cek4xy7cIOBOEiarQ5uME9c0Rjuh3AFFmSue3+etUzCiVaysiwEgK+I4GxYbDQDiMaELS2o0wSc3s3fFZKaMHcnw4cMK9IHoi6FDRzN8xEyWrNzJ2Rsh3Lp1mStHt7Dpz9mMHTWS4RrG3W9jpi1g5qZTHA6MIs1idz/O0+K2kxpxkZMLf2dSl7Z8334xo5ZeIDzZgiPXfRDKuEUpf5InaVGqciO6OKyqX5T9omTSh8A8GABkNgp0jthpndgyI4m+eoC1w/vRr35Tho1ZyuqDgUQkpRIWeITDc7sztHVdPqz6Bm+Ve5mXXnqJF198kRdfFPXXKV/pIz764jdGzFzH8cvXOXtsO7vmDqRzsy95r8qblHv1Zd4sX4EadT6h3q+D6TH/IPsvRZFpd2kHl5gMy4rxZf2iMdR4uwatuw1j+4VIQtMc2oIYGbrsbHFQOO1ppMdd5vSGMUzt+CF1K5SljLcX3l5elCjxGD4l3+LrFoOYv+ciFyJTsdhsWM3pRF45ys7p7fm9WQ3eq1GNnzr2YenfJ/C7GUVUTAzhF/fit/dPFv+1mZV7fLkUkaQ9dRBzIcJ//k88ysx1YM1MJzk8jOg7dwgPDSU0NJSwsDBtE3U3HUJY2G1Co6IIj08n3WzLW+xzF6cyANS+5wpA+HSSEXeLcxvHMqdXPerXrsjbb77Cy/l9IPriVV5/ozrv1W5O5/6z+Pv0Rc76HePYmomM7NqETz54mwpvvspr5cpRpfr7fNb0N1qP28iKIzeJz7TiFONrbg53czOJuX6C9QNbMLhlEzpN2MzSo6EkZtq0gVhtv76u0iJHxdH5eSwEq+qLukqr9ouSSR8C82AAkNmQCc+b9MtxWIi/cYATfw1lUOce/NRsFAs3neZiZBpZVhsZ8bcIOrmGVWPa0O6Tl6n0wsOU9BYHWQlKlHgI75IvUaVmE3qOXs7mwxcIjk0gMuQql49uZNHIVrT88g1eKFuG8lXe4+dugxi3ZDtbTwdxKzYDmytHm2C0Z8aScGUHSyYNo2LFZnTot5jTIckkWz2X37LT3TuCOBCduOzpJNw8xNGVQ+n0RQ3eLF2SMtoAUBpvn2eo3qArvVad4sitROxOBzmONMLO72dZz8b0bvI1bbsPYfqa3QSGxpOSZcNuNZMZf50bp7ewYvpQJkyezORtZzh4LQ6T1VlwFWKug1xHGpGXTrF72gSWDB/K1PHjmThxIpMmTdI2UXfTo5g4qT/j5i9kyqbTnLwRi8WZow1+RQ8AYsd3YctMICpwD3sWD6DfD5X58M1HeaSU7AMfSpQoy0uv16VFt4ks3HKCSyExRETeIdj/AJvn9qdXs3ep+uZTPPvCy9T7uQMDp69g5f4LBNxJJNPmdD/Lz3GQa4vjtt/fTGhdn04//MCY5QfYdz0Zk9Wl9ZM79+4dSV9XadlXyi53zwFclEzYUu3padV+UTLpQ2AeDAAyG3kDgHvGPxtrRgS+O2cxs299OnYbTIex+zl0IRqTzamdpVzOLCzpIVw5uJgVf3xH45qvUra0DyW1AeBhfEqVo1a9Lkzc7Mu/wUlkWsWBZCI5PJD9C/swrPUH1K71Hk1+7cWSHcfwF5NNmVZsTvfBL+IwJwVz+9BsZg/rR7WPhtFv4h5uxmdqi2GUc662U3h2jLvczXHgzIoi/MJuFvRpww8VX+H5Rx/Cq4QXJbxL8ey7X/Fxj1ksO3CeJFMaaXHn8ft7If0aNOS3n7owdfVBjl2LJsNiwyVmtHOd5DhNJIac5ciyIUwd0p1WA2cxY9MJbsWZtJzkPxHJtZPrSCb49B7W9u3GmHat6d2lC927daN79+706NFDK0W9e/df6d6jKZ2HjqDX/H3sOh9OpljReLe4KwDRerFoSqzUSyD84i52Tf2F7vUr89rjD/GQlxiExQDwHG9UaUDvmVv551I0cSYxt2IhKyUc/+0zmd39M374siYf12vCuMUbOXzxDlHJmZjFFZi4tBdeXFYc6Te5eHAVXb9vSPPv27L4bz8uxljIdoj7/XsPSrlL6WXqAapiZF1fevrULdHb09MCJXWKkkk/AlPoACANqKX+Xk7I1Hu7wmiJkaW8YpS21YAET/3p6aJk92NP6uuxgq/xcnNwZMWRdOcIiyd354evatBt+FRWHA/ndoIFV96OcfduDjkuCxnR57myfz7DW3xN9cfK8IRXCbxK+ODt8yRvfPgTP0/fzcaASDKybdqZNjHYl1X929D7u09p12c009cdIDAknrS8y19368Ulbg5pERfwW9mbSQN/49NOi5iw/hwxGdk4PA8ftObc0xZxGe6yYooPwn/rHCZ3aUjV15/Puw3wotSTL/DKe18wbP4qzoUEc+nYPNZP60qD+j1p33MZ+/xDic6waY863XlxX3JbTbHEXN7NtvmjaF2/Ef3+mMJW3xCCE7NxymXId13czbGQHHGL83v/5uDm9ezYuoWtW7eybds2bRN1N72RrdvWsnX3PnacvMq1iGSsLvdCn+KuANz9KOJyYEm5Q9S5TSwZ9Aufv1SW53288C7hTYkSZXjmzTp8M2AxM/bfJCwlC23gTr7F/vkjGPL9h/zWoTsD52zi6MU7xGdYtMedanpzHFmYo09zYstcmnz1Gw0ajWTL8ZuEmxzY85Yli/zLn+wLUcrjRZujyZsrkO8JaJPMCiZfTxpSDmbJkpjCaMEXGFnKuoqXdYkxGADEiO/Ckp5EQsh1gm9c5fLV61y9doNr165zJfA6QUEhxCYmEhMTSdiNKwRdu8q169e5fsNdXr56h6A7USSlJBIXE0HQlStcvXSdK1dDiUvKwOLMRTxB+08apAYu60YNVHl6+1JPNl7Funli/bmN1LBzXNw+lUFdW1Pzi0aMWLiRC7FZpFndZ+d8/VwXOdZkUsP92Ty5Px0+fIc3n34MLy8vvLxL8vgbNaj88yDG/3WI4PgEEqPOceXwEoa0bE2b7zswbdUhjl2PIzXLrp1p83eju+K+00zMtaNsHdGMEd3b8Mu0v1lxKpRUi5h8U1tybx7hLmItu8OSRmLQCfavHE3rr6rx+lOlKe1TAi9vHx59qiwN23ZgwsKFTB76C4O7/EzzbvMZu+wsN2MyyNZuQ9x+3HnMJdeVjT0zgov71zKhbQP6dOjDwBn72ecficmeg1PrU3FQurBZMkmJjyE2MoLIe56QyCcmYvY9gsioGKLiUsjIdA8kwp82CRh1nI2LZ6DNAfRahF9osm4loHaTTq7DhC39NifXz+aPBh9R69VnKeUtBgAvHn7mNcp9/Su/TV2Pb1AECfG3CL+wmQWDe9Pys6YMG7+Cbf5hRKaY3U9W5ECWl2KHJZX4i5vYuWgoDZsMoWnX1RwJjCbVlmOwD4urgVzs2Zmkx0cQFnSZ8+d8OXbcn6PHr3ArLJkMq0ubOHQ5srGmxxJy8xLHjx3l0vVbJGZayXaK/HkOYrWn3f3g6Xw9LbCqrqxLG0a0bgAQDcghN8dK/O3z+G1ZxNqFM5g0bTZTZ8xm5vTZTBk3jz//3MzxswEcP7qPv5fO5s+505gxexYzZk9nxuw5TJm7jpWbDnDhyjlOHd7F6unTmDV+HjPnbuXk+TskZLuwFTF6uhvifhnE6bBjt9ux2d2lqMvNZrPl1zWMzYbKE3Wb3YbDKd7UKnrhjtunE5cjneB/t7GhX1M6NmtD3baTWbAzgHiLMz/m/ETnTXjZMuO5eXQdy4e347Pqb/JQSW/tbOvzyBM89UY1Og4dz76Ac/x7YCHbZ7WnZfM+NO+0lN1+IcSYrNhdeZ2edzkpzt4uawzXT2xiSouv6NOiBaPWnmT/9WQybeK+U3apuyxsR8h12bFnxXLbbwcLezWg6bvPUPZhH7xKlMCnZEleLPc6VWt+SPWqdWjwQwfGLTvMocuJJJsd2gy4dJNvX+wbLgvxt3w59ucQhnb9nS++m8jMlf8Smm7D7HTnWBwE4oUm8QafXUwyWq1kZ2drpayrtNZPNof2Rp12hszNxWVJIDPiMOsXTqHWB7/Qrtc8fEMSSLHnFIhNe+aW6yTXmUVk4GF2z+vPL/U+4MkypfH2KoF36Ycp8/wbfN2qM2sOHufUv1s5tLwHA7p259umk1mwwZc7yRbMDnnrJVrtvqzPzcnBnBLNlV2TWTa6NY26TKDDlIOcC04iO2+uIj83Wle4Bz9TUiRBZ/awc80sxo3qzy/t+tO89VSWbvHnZqKVTHsOdlMCSTePsmnpRNq0/pmJc5dxNjSFRLOzwDoCtacL+jIa+P9HBgD3WTDpznkCts5lxqDuNGvQiIbfNeD775rxzVc96dN/MXtPBXDqxG52LBjJ8F7tadT4B75rUI8mLdrQafA8Zv91kPPXLnBk03JmtG1J/44D6TtxE/v875CcnYNdeXwiG+lp4F2cNgvpcaGE3ryIf8BZzpz1w9/fn4CAgPzNiPbwzuLnd4az5wIIDIokPCELq+5lGeFP/d3NteG0xnJh51ImNahF28a/0nzENracCcOsdLjQ8ejeRYzm6ZEXObtzLr83/4R3XyzDY6W98fL2ptTDZfjwm+/4fdQYBvVpR/9239O+z2xGLfXnWqQ404pLXtmZ4ixrxZoRTdS1g+xcNIxfPnqXpl83ZNiiXey+EEl8ph2bsgBJxuKJx90ijdauJKykRV7G76/RjG37KZWfeUybEBRXKeLR4MOPPcMLlb/jh87T2XbqFhHpdqx5B7LMjbDlti+uLHKwpIQSdX4Tc4cO4rNqLek/ai0HbiYTk2nPnxWXOqKUl8KSp6clXyvzFl5lJgQR9O8aZo/oRbUqX9Ok3XC2nb7GneRMrDnul21kfO4rnhyykoK547eZmf1b8kn5p3nuUfHo0xvvkqWoUK0GHfoPYtCgXgxsX5/O3YbSc/JB9gdEk+kQg4rsA7FPiGPAjjktljuXjrBqQgc6N/+Eum0G0W7qLo5fiSFFXrXl50ZEIwaAHLJSYwg5f5S962YyfvCvfPN5fcpXbkKvCRvZdzWBOJMda3oMcZf/Yd6YblStUol2fUewMzBGy798q1PkQ/3JPEmenhZ8qVOUTNXXXQHkJSHXRXZqOJEXdjF/cGe+qlCO8i88xzPPVKLscy1p0mYpR84FE3zbn4B/ZtK/4w+89trLPPNMWSpVr0ProYtZcuAyITHhnF23jJlffsHADoMYvPo0J4MStR3Ms9N7GukJOgdLRiLBZ/eyb/08ps6YzNhJk5g6dSrTp0/P36ZNm5ZfF3xBS97UqVOYOHE0U2ZOZ+n2ExwJjCU106ZN7MhEyWTJhOTmWLBnBXPirxn0rFWV1k0603vRcQ5fjc8/S0sdWQpdccvktKYSc+M4m8e2o0vdV3jjqYfx8fbSbgeeKPsM5cpX4q3yNfmwbnNGLdjFkespBc60WtvFLYUtnbToS5zdMZtZ/ZrxTc0qfP5lQ3pPWM7GY1cITrJgsuXmt6Owtrjjc+/MDnMiyUGH2DZnAA3fKccrD5eipPZUoASlH3+O8vV60Wn6XnyDErQzoTYBpux8Wmz5l6W5uOypWJIusm3mSNpUrUWnbuOZtv82l2MytWWwam6M4lPtydzLUqyGFJf/CcF+HP1rKsM7N6dm9Zo0atmd+ZuPExAch8nh0l62kTpaKRYGOTIxJdzg6PJRDP/hbWq++hilvb21Pijz6GO8XO5N3qxQg3erfUP3IQvZciaCkLz5C5EpT1wuXI4sEsPOc+qfRfTt2Ig6H9aixo/daDvuL3acuUNoklmbsPXoiCjctwAOm5n0pChund/H7lUj6dD0a956szo/9pjCvP03tYlTq7gCCDrCwol9qF65PK16DmFDQCR3UtyPFjVrSh9IWs1tQd9aFv6HBoC7ubhsGZhir7Fr4Qi6f1WRyi8+ho9PWbxLfcHXP05jb0AoEbG3CD67hoFdf+TJJx7F29uLsuXe4avf5zN1z2VC4sI4tWYVI+o0YmzfmazxDedWklmbSCu8QWIKxkVmciSX9q1l3Yxh/DGoHz379aP/gAEMHDiQP/74Q9tE3YgWvAED+tOnTw8GDB3KzPUH2XcplhTxsow7T0pn5zGAHHs6lqQL7Fgyiu+rVKT+j134fcUZjt1M0ibE1ISrHaGN/LkOzMmh3Ng3n8V9G/PJWy/whDj7lCih7YClHn6M5yp9w+dtJ7P24GWiMhzamVxOOLlti2XHWWQlhxHkt4e9f81l+sQxTJ21gPW7TuB3LYK4DBsW3SygGpdsjRqfdu9uiiDw8Bqm/laPr6u8TJnSYpa8BCXLPM1L77fh54FrOXQxkmSLC4dLnvHd1grYF2e8HDNOaxhHF09gQPWqtG3Zn25/+nEyKEl7hKn6FhYK6BvQMmYNqw2CJtLjbnPl1B62rVrI5PHjWLBsDQd9rxMSm4ol7207VU+ri3UQ1lTCz25j55SO/PxhJZ4vXZJSYk7Gywtvn1I8+ep7VKvfj/F/HuJ6bKY2mMonGJ44xQSvlfSEO9w4d4A1f85l1PhJjF2wlhW7TnPudjwJGdZ79gktfu0jJuL2J5v0xCCC/Lcyo09rvqlYia+aDKD3/OP4BiViyc7AFH+Df5ZNpMPn1RkydBQ7AmMJTXdfRUlbahs98bm5elrVKUombQqM8RWAdtnmwp6VyrUjK1k55Hs+r/EyPt6P4uVdiY/r92XVkctcCbnO7YC/+KNbE554rIy2Q5V5vjxvNx9Pz0WHOX/9LH8vX02Xz/sye8pWLsaaSG5qOm8AAB+OSURBVNHuYd2HoT5INy0OCSeZKdEEHtjC1oVTmDJlAmMmTGBC3vNj+Rx5woQJ2vNklZY8UY4ePYpJ02exdr8fvndSyMh2FjkAuLKTMEWeYNWs/rxb4Q3qiAFglR8nbqXc09kiVvUn7nudtgyyogM4sXEqnb6uydtPPcJDeWsDSpZ5gnJ129J0+Fb2ngvHZHPlD4T5HScOrlxx9snGkpFMclwUkRFhREZFk5CcRkaWmC8QX/9RPd97gOXbkzBtSbOZ2GtHOTy/E50bVOWJR0trcwFe3mUo/XhNan0zgLlb/bkYJR7ruR/FyRYW7CdxrWwlxxGH/+oZTPq4Oi0a9+DHCfvZcylGu1WSB5R0X1DfOF4PNm/ux27BnJ5CYlwMEWJBUWw8qRlmsm0O92IhqVCgFLdQNixJN7h1cg2jf21I7Zee4qnSJd1t9SnJc+98ySedF7JoVyCx6SKfnsHOE6e4bcnBac/GbEohPjaasPAIwqPjiU1Kx2QWL1F55gzUfcFtQ0ykC/0M0uOvsXv6UH6v/R5ffNqJxn03sNs/nAxbNtlZ8fhuWcGEJvVZNHUWx+8kE2P2fNhFtSua6YnP3Wg9LTGyNNJ3a3r0Cx0ABMTlsJIUdJxT64fS5Osa+PiUxsvrKarWbcbwlfvYcWQPp7aPpHurujz+6EPaAODz6KuUrdaNBp3msWnzYhYuXEi7zotYvvEs8Vn2vIk0TwBqkJ4GubBbMogNusJVv5OcOnWCYydOcEK3HT9+vABP0Crv6NGjnDh9hsDgKO1lGfGMXf48viQHnJYE0kIPsXRabyqWf4NPW/Rg7PaL+IelazudqqPGLSwIWtw35tiSCL2wj1Uj2tGybgWeesR9oPmUfpSyFb7j09azWXfwGrFZTvdtRZ77AvbkfXNOTv79c/59syfc/Joal2QWsIeYvMsm9upBDs9oQedv3+LJR9wHhXhe7uX9LC9VrE+T/itZsu8GEal5S1yV2Dz2xLBgJ8eZxuXtC1jQtDY/N+7KV/22s90vXLs817+vr49PT8uYRSllshTtzpF5yLvfFrLCfmIAzXGkkxp5gd0LB9On0ftUePEJ9yNQbx8ef6km73wzlPHLj3MrwUyW3TM5LH1K24KWeZel+PSaqMsIjHTc+mIwd2AzJ3Bp20Lmt/+ebz9uw6dNZ/DX4evEmTPJMoWyb/0mfqvfn5nTtnAlLpO0vMlIYUPfTiNfRhipW5hMbV+RA4B4PdWWGsRtvw30aFOPF554iNI+JXnlndo07juZIRMnMWf4L/za5GMqVniNxx9/VFtpVvLxb6n6fnsG9G3H0Enj6THnIDt8I7QFFuoMduENukuOeDU2M420xDjiYmOIjokhRrdFR0cX4Ala5Wn1uDgS0zIxZTvyn2sXliCnJZ60OwdYMrUnFcq/ztetezFj92UuRZnuawBwLxu1kxJ2njOrBzKk1Qe88HQZvMTaAK/SlHz4bcpV+YWh8/ZyIiiFFLOz2PX0amfpO7QomRsrdlMxSWnGnHyby0dWs/SPpnT8/n2qv/MmLz3zFI94e1HSqyQPl63AK3W703H8Vo7diCHRLL7B597NC/aT4Inv5GVyY/8ylnf6mGYN21Gn7Qr+OhpEss3pWROQF2BBfc9BLuNXSz1WyNxt8aD0tEcisGIizkl2WhTX9s5mwe/fUrPCc9p8TIkS3viUfoWnXvqOX/ovY7t/BKHJVi1eLVMFJvTcVvW+9PEZ0TIe91VhJhFnt7NzSmcaf/4TH3zWj4Xb/QhKjCE+/CTrV26k4U8rmLb4LFEZVqx560yEjf/Ut6qjj0uVeeIr4hZAUxCXo7YU7essi4f+QsMqT/PCYyV5rOzzvPHep3zwaXO++6ojnX7tRs9e7XivRmVK+jxCCe9Xebrs23xQswrt+/Zn1t7LBISbCrw+KwNSG+kJ+i5OuxVTQgRRwVcJvHSRgPPnOX+h4Hbu/LkCPEF7eKIewIXAQK4GxxCRmKV9N09tvOpb8J3meNJu72fJlJ5UeOt16v7UjVEbz3H2Ttp9DQDisu/uXStJwWc4Nr8zA358m5fKltHmRrxKiMmoJ3j82ff5rO0Uxq4L4EasyT2jXciOp8bnyY1sgac0krl5ebPSyaHcPrmUjQuH0KXHAH4fMJjxYwbQ6uuPefvhUjwh3hUo/TgPPV+Nus37M2WrL74hKdonxqRtUbp/ohT3yGZuHvqTlV0/pPEnP1Dls7Es2nGBSLMTq26hgrQhI9bTki9KI5nHd14E+bGomnky7eUdB+aUUC5uGces32pT862nKeXj7b4N8HqEUmXepPq3vek+8yCHAmPIUp7wFOdLH58RLaMSshyHldQ7Jzm9YTQtv6/He3V+ZPLavZy+fplrJ5ax9a8V/DH7JFtORJJudbq/JJRnwCgWlaf3LdSkvCiZGl+RVwDuxxpWLZknV45gdLN3qfzSE9oz5FJlHufpVz7nnY9GMXT8CrZsWcKvTb7hlYcf5mGv0pQqU5ayr1WhVZ9R7LkcRaRJ3LvJncgdgj5ID51LdkYSYf4HOLZ5MYvmzWSqmOWfMZ3pyjZt+rR7aA9vGtOmT2HewiVsPOCP360kMiyOQi/dRETiFiD9zmFWTOtDtfJv8FGjzgxY4cupm8nuhTrKgSoTndcS7czjsmeRlXSDqyf+YtnIDvRo9hlf1n2PiuVe5ulSJSnt5UPJMs/x7LvNaNh7Mdv9gglPs/73J86UuNTO1V6XzYgn5PxBNk3rzciBveg4ei0LNh8mwO8Qf47qQ+vqb/Lmk4/g7e2DV8mHKffuJzTtN5Nle/yJTLFoz7u1Z/P5B13BAWBFlzo0qFGP8tWGMGeDPyGZDrL/PxsA7iKuWrPTw4m8so9tcwcy5JdvaPR1baq9/SbPP1qGMl4++JR8lCff/IKazcYyc8tpbiRkaS9gFWynZx+VORWlZx/1yNV9QV8XazGyE65w/ehiujX/hjrv12bg9AWs2b2L7X9OZMuGlWw6E8yl6CxtUlg9QlRb9+NbYmRppO+O2v1XyIsZAEQ4udgtKYT7bmD9xHbUrvIaPtpKt1K8VLUB3/ZYz/J/znLlwlHmdW1Fg2ce48WSPjxU9k2e//A3ekzdypWYdDJ1z5aNghQBicsmMQmYERvEmZVjmNm5Pg2//JhatWtTW7fVqlWrAE/QHp6of0C9Rj8xeN4WdgREk2Qq+MksfYJyrClkRp9m09w/+KLSW3zTuAv9V/hy8mZykZOAImZx9rekRRB8YiGb5/1O1z5D6Tl4IosWTqFv28bUfvoJnhWPBb1LUeqJ16j8eSsGLj3AvstxpJnt7vvK/IOs+B1N35GetrgntcR9qi0rldirh9jz5zQ6Nu1G+98msXRvIOdCEkhOiuLygTUsG9SCT6q9Tkkf90s0jzzxDG9Ur0v30bM5ejOe2EwHTu2+V+6a+gHgIxrUaEL5alNZuPkyUWLB1H0P9GorPDulpy0enorUyzVZ3r7jtJqIvrSdo6v6MWTwIDr8Po7ps6cxbmBn6pV/jXKlfLRVgj6PPMcLlT+n7YglrD0dRkSKhRztvQfZzsJ9q/5FXU/LWDWZ+MxbVjgRF3cw9tdGfFulEm27dqHP+GkMHDydpat3cSEimaRs8Y7Jf8+38Ctj0celytT4ihkA3FCXw4Ip6iwnN0+h+cfv8mLph3i4dFlqfNuBgcvPcPRaNHHh1zgwaQADa5Xn7acf49m3PuDjTguYvu0SMenZOHSJkgHJgD103lOAhDAubpvPqhGd6PZrK1q0+Jmffy64NW/evABP0CpP1Dv1/J05Gw9x/EYS6eairwBynSasqVc5uHIiHWq/w49NOtFl3lEOXHavA1DPEGrc4qxjSY8h5OJh1k/tx/Denek5bjVzt5zi8lV//l40kd+/+YAaL5XVJqPEMuFnX3+Hz34ZxMQ1+7kalUqmTczue3YAfQfqadmJnrxJXfcsujUziahbZ9m1YhzDe3SkfuNh9BixjbO3k0i1OrHbLdoS5rM7ptOxfh1efbiU9hKNWLz08KNP8vF3HRi55BTHA+NJy3Z/As3tU/jx3AIs71qXhnXbUOXzJazcdYskm0vr68Lju3dwKwor26fHqLSGyc3Fbha3qxfYv2oKE3q1odfw2YxacYSTAQGc/GcV41t/z9cVXuZR8VTAy4dHnnqB9777hR7T1nHsSjgp2U7D21TVl74fjGiJd8tyyHUkkRh8kmX929Lmvdf59uuPafhrd7qPXMVfuy8SnWbRBk3dw538g7mgPdnPxnkUPsVPH5fkSVuSvq8BIFe8XWaJJOj0FsY0+ozPnn6e5x6vyvdtRrDu1B2Cki2YUmK5+vd8FnarT60Kr1Lpg6/oNXc3uy7FkWF15n8jTR+ADFgG5KbFIzUzadF3CLt6jgsBYlWf3z2br69vAZ6gVZ6on7twieCoBBJNtgKda5igHBvO7Fgu/LOUyU3q0KppBxoP38Km06GGKwE1G7k52hOLqMuH2Lt8Ch2b9aR5q3Es/TuAC+EppGekEOK/hx0zevPT5+/yUN69aOkyj1H2tYr81GUQm/69SXCSe0mwGANEF+rj09NGeRQY8STCZk4lNugMhzfPpmurenz8yec07jGTaRsCuBOfhVV8tDLHgdUUwZ2AnUxs8R2fPfEIT4krlBIl8PYuzdMvfs77X05j2jI/rkWZ3H2oxSb+uCcBrx1YxpIuH9OkYUfqtPmLjUdDyLC7tKW6RvFJ3v20RWJFKfDqT6Xdttzf8E8KOY//zoWM7DmA7+v1Y8LCvRy/EUdcWjqxtwM4sWYc/Vp+yYtPPYqPl1gOXZonnn+VOvWaM2fzMe1DK+6l1uKs7vao+pKxqDy3f09898pyITeLjNjL7J7Wg/5fvE6dd8rxWaOWTFxzmFM3xcdV3K8eq22UvlSekS/Vn6qjx6oyaVNg7msAEB1+N8dE/K1/2TakBd0+q0Olqq1pP3AVZ24nkWJ1YTWnEXdpJ9vn9uOz2l9R66uOLNh9jsDYLO0+Uu7U0rkMSG2AGrSoi//K4nQ4tE18lkm/ifX/Kk++IyB5Gu1wf75KvJHl6aZ7DzB3POIRkolw/13sGNmaLq3aU7flROZv9yfOfO+7AGIFoNWUSMzts2xfNo4/urahwU9D6TR4C8e1F0bEf5RxkJVwgxvHVzP8lwa8XaY0j4k16mKRkE9JKn/QgC4jt7H1aCgJJvcyX5mHwnKj5tCTR/cz8PTYGwT9u4kti4bT/7dGVH+7HM++8ga1G3Wk7/R17D8XTniSiWxLClHXjnNo+Th6f1WL9x55iMfzBgBxdvQu+QaPP9OIBi1mMHvlGS7cTsKc96aeWDLtsifiv2U245vUpGnT7jQYsotdAVHulYTy6MkLVLZHxq2nJd/TFrWnihoA3LeM9mwT6bE3Of73Uib2b0vLlr1p1HEp6/ZfI9Zkw+p0acuroy/vZunortR95Tme9RGLtMQtmQ/Pv1qZpl3msmDLVW7HZWkvq8lHmWofGMWnb4uKd8vEed1GVtJtTizoy9gf3+WLL7+kUc9RbD19nfA02z33/jIfqq378S0xsjTSl7Yl5v4GAHH+vusiM/4ml7cNZd6IrtT7ZQ5DF5wmJCELe06u9qjJEhfA6V0raNZkEI1bzWTv+TDitMtHd4caBaTyRF2lZZBq0GrdCKvyjOxJfSOZdi/vcpAecYHLO6cypGsHPvioDSPn7eB8jJnU/LcBxaM1G9pl9o1THNsyk25tvqNmzVp899sYxqw6xcWQZLLEghrx320yY4i4cpAF3VtT/8kyvCheV81bilvmieq88e4f9B2zF9+bCSRkul/DVW83ZB7Utsl2eGQuXHYTEed3sn9OB/q3/YwP36vM66+9wosvv6J9eKRhu35M2ejP6VvRpKWE4L9tLrM7fEuj9ytS/vnneOHZZ3jmmWd49tlnefbZV3juxWpUqvYrTdv+ybbDQSSJl1jE58dcmdgzb7Nv8Vg6f1CNn1r0o/PC05y4mZj/MZN74/Mc1Ea5l3gjmb7dEiM+o+7IziAx4gqBR1Yz8Y/21Hm/Cp836UKP6bs5cD6CFLMdh/jXXtkppESe4+9Zw/il/CtUKl0y79sNJSj10As8W649TTuuZeepEO1TX+IqSbsa+w8HMzVWd5ziC0k2TAnBHJ37BxPbfkurvmPpv/ooFyOSsej+o5PMg+xXPX2vfU9eVR2ZI72+nr7PAcCtZjcnkXRrN2cOb2H+Ol/++TeKNLP79VRx6emyRBN28xxLl+5h8YqTBMWkYREvbuQlUQ1eBqvy7idofQP0dHH2JL4wX+JZvs0UTcLNg6yc2J/W33xLj2FzWHAkmFvx4lt84ms8LsSZ9ubxNWyYM4A+7b+jRuXXeerZF3jn0x9oN3iWttz3WlQqZkuq+0z75xgGNPiY9x4pzVPiCiBvACjh9TylH/mE2l8MYfDEvRwJCNfu0eW35oqKt6DM/U3AxJAALu1ZwJr54xktvlWY943C4SNGMnvxGnaeCeZmdApZWfHc9tvHnsWTmDNhFMOHub9pKL5rmL8NG8WwEcuYOf8oZy/HYHLm4hQrHi3x7hWTE//gm7fr0L7bJBYcDuZGXFb+ZKmMTZT6XOvporBS/16MuPqKI+L8P+xfPZbRfVrw9UdVefrpJ7VJzO9/G8asDcfwC0ogRXyeLOoy/jsWMK1zE756sSwvl/TGR/t4i1ij8SheJd+lfNVOdOy7jg17rhGdnu1+Jv/fHQC0pc0pJNwJYPGIUXRp1o3hC/9mc6D4QIlY96+/8/e0VN2XZR5UnlEepbwomfQgMP/RAJDjsuEwx5KaFM2dyFRik7NxiK+gap0sXiPOxpyVRlhYHGHhyZjFV1Lz3vqTDZDOJS0DNqIlT9VR66quxKo8UVdpva5eJvHiY5zZGWGcFWfIHk3o3GMwv03ZwYHzYaRZxBnaTtytE5xc0Y9x3Rvyzed1qF6tCpXersy779emUdseTFh9jKNXo0nLiOHqkb9YMaAlHb6tw/uVKvJ2+fKUz98qU6FiLWrU+pUffl7Emp2XiTHbtUkhNT4Zm9oGWZcy8STCYc0kKyWW+JgIIsLDCc/bxPf4YmLjSTG5vyLsEo+nTKmkxEYSHeHBCbz8dl9YmODHERWThinL/b2+nFwHmbE3uH1kGZMH9OLDOi0YPHkdZ0LStFdZ9S8S/U/1i2yr2557sU9m4m0Cd05m6bBm/PT9J3zw/rtUqlSJquL7ft/9xIDpG9jmG0pUcpz2z1b+ntybP5p+zqfvVqaK+Epyfh9UpHyF6lSp3oTPvp3IxHnHuBVvIkv3vx+Kbot7XxO3hdqr0A7xz1wdOO1ZZEQFcunQBgb3mkrLtvNYszeQ4HSr9vkzcaVX2E/t/6J9eyxIHblPeCTGt1L/0QAgXnUUn2Fyic8x213YCzzaEw3J0S55bTYHNvFNtbwPRqpB6QOSMqMGSp6qo9ZVXYlVeaKu0npdvcxNi3a4cDkzib9xnNPrJjGyWxdaNe/J7LWHOBMs3ikQ3wS8TbDvNg5sWcaihfOZO2cOc+bMYe68eaz8awsH/W8TFJuOJTudmFsB+P69ms3LFzB/7lzmzp3rxubV586dz9x5G1m28hQBl6NJF/94RBk4jdpWaFu0NrsfS8rlq6KUy2ndOfGclcWHQ8R773qsxLt13ctfuSs+DZZOmP9+Ng3uwKDfutKy91xW7hZfKrJrH7P4r1w2F9qWPIFRP4l90ZqZSHTgQe22c8XSBcyb58nrkmUr2Hn0ApdCk0nLyiA1NojLB7eya/ViFs+fy7z83Ht05sxdzfxFBzl4PIgEk/WeQdioH9z5FBOjYs7KSY49C0tmBolJ6aSkJJORFMq5nStYMbgno4fOY+rSf/G/lUSmeKFJU/u/agAQB5QYfd3/oFEMXgU7xy33fALJs6PJ5BXV2fnJVEAF7SuCQmaHVbyRPWnBSObRFWvAnTgyY4m/cYKNE4cw6KfmjBw5h1U7fbkdm4bJYsGSmUpGahKJiYkkJCRom6gnp6RqL+5Y7WIQdOGwmjGnJZOalKBhJV6UcktISCEpOQtztvw32AUHL6N4768tbpSnbffSRjKV5+7zHJzWNNKjz3NiwzyGNG5I/+5Dmb7ZjzPiFW+H+JjnvbYFRx+7nnZreXRV31JfjxHPSnJcTuzZGWSK7/wnuXMp+kHkNCkpmfRMCxbx8pB4Fu+wkp2RRnpyIol5GE/u3ToJCckkJIr/9GvVrmzFxblRLCpPtkWULrsZS+ItQq/6cvDgMQ4cOMixA/+wcuIoJnTowKrlWzh9PV6b7BX/QVikS7WltrGwdqt46VvVk/KiZBIvMP/hFUDBnbKwIKUDKVeDKkymx0qc1JW0WuplglZ5elqvq2KFrACd9109W0YsQWf2sXfBFGb16MWsoRM5HBBEaFrBGXt5BpU+ZZnvUwya2jJVd4xqXWDddD5ai0WN5x57Hug92Hvaom+bjlb9SF2VJ+ZFcnOtmOJuEPjPTJaO+51W7f5g1OwtnLoZp72irF/DoIR3T3z/s21x51PaLJDXvHbmt0XsH/Jlnrx9Rcikjii1p0XKSTlfN69B0o9sn6RFac9MIO7CBvasGErPLh1o2aIjv7bvx7DBk1i+ZD1+F26QoD2V8HzVWW9f2hWlXiZ9SYyeVnWKkqn6DwYAmY17Ep63szhtWDPiiAn8lz2Tx7B+7HiOBdziTqp4vOSZwNEnXE+rnaOvF0YLG/JnZK8omapbmH1VX9YlVtXPcYqvFIUTdmkv2+b9waRRg+kzaxtrj94gLiPbvZRZMaDqGtn7n26L4vp/5aBR2yfbIkrto6lnV7J9Xk/aNm/Et/Wa81PLAUxbsI3TVyKISzPnv0YsY1ZtSZ4s9TLpS5UbYYRcj5U8qSvpBwOAkhHDZObNe9hMyUQHXuDO+fPEJKRpH3d0yWteg4QX1wGGvnSxqBgjexJuJFN1ZWdLvJ42wqo88WHMpBsH8Ns9n1kL5jNj1Q52nw8hKN6kLSoST3k8Q9V/7cwlY/uvtEXq6tslabUtRdkvSiZ96DGSFqVYhmyK9Cfw+Bb+XLyYRUvXsXnXSQKuhWsL0fSfWpPxSdv6UthUf9KX5OlpwZc6RclU/QcDgMyGkjzJcifTPcEjLoOdNhsOm037/2/u2W6JvHfELa4DZEdJC0a0yjOyp+qqWMH/T2gjrMpzZKeTfPs4l09tZuP+k+z2DyY6zZz/5WAVW5hvFSPqKi3bIXX1suJovb6eVvVFXaWlT1kWJpM29fr5tLiVcNlxmJNIjg3j2pXr3LwdTmyKiUztfykKv8X3i/Qj49HTanz5vhWQlBclk3CBeTAAyGzc50GjJlhR1XYqKRP84jpAxUr8f2pP4ovzVZh9VV/WJVaNT3ybwWZK0L5zFxmfTFyaRVtdJ2+AVKzUL8qeUbwSbyQrzr7U/a/6lvbv17fES3+S1uYXXA4ctmyyMrMwWzxfcJLncomVMetpyZe29bSKF3WVVnWKkkmbAvNgAJDZeDAA5GdCv/NoKyTFo8Ic8ZjX/dKS+vy6sJ1QGrzX3r07bmFYwS/OvtQtDKvq62NRdYqSSR96zL103lOyvMlGNU+qL9WerOtLYVv93evr3jxKHT1W2JEyaVPQDwYAmY1CEqSIC5zVjZKp8kRdpfUdUJRMYlWMkT0Zm5FM1ZX2JF5PG2FVXnH2VazetqRVjJE9GZuRTNWV9iReXxphVV5R9ouSST96jBFdGFbwBV796emiZEa+9PqS1mML8/1gAFAyLpMnWUa05MlSxao8UVdpfQcUJZNYFWNkrzDfUl/Ki6NVPxKr8ox86+XF+dLjVVqvq5cVR+v19bSqL+oqLbCSLkombeoxRnRhWNWXipF1fSnjknwjX0YYgddjJU/akvSDAUDJSGHJlBA1qUZYladiVX2juuCpupJWeUb2VFsqVupLeXG0ka7KM/KtlxfnS49Xab2uXlYcrdfX06q+qKu0wEq6KJm0qccY0YVhVV8qRtb1pYxL8o18GWEEXo+VPGlL0g8GACUjhSVTQtSkGmFVnopV9Y3qgqfqSlrlGdlTbalYqS/lxdFGuirPyLdeXpwvPV6l9bp6WXG0Xl9Pq/qirtICK+miZNKmHmNEF4ZVfakYWdeXMi7JN/JlhBF4PVbypC1JPxgAlIwUlkwJUZNqhFV5KlbVN6oLnqoraZVnZE+1pWKlvpQXRxvpqjwj33p5cb70eJXW6+plxdF6fT2t6ou6SguspIuSSZt6jBFdGFb1pWJkXV/KuCTfyJcRRuD1WMmTtiT9YABQMlJYMiVETaoRVuWpWFXfqC54qq6kVZ6RPdWWipX6Ul4cbaSr8ox86+XF+dLjVVqvq5cVR+v19bSqL+oqLbCSLkombeoxRnRhWNWXipF1fSnjknwjX0YYgddjJU/akvSDAUDJSGHJlBA1qUZYladiVX2juuCpupJWeUb2VFsqVupLeXG0ka7KM/KtlxfnS49Xab2uXlYcrdfX06q+qKu0wEq6KJm0qccY0YVhVV8qRtb1pYxL8o18GWEEXo+VPGlL0g8GACUjhSVTQtSkGmFVnopV9Y3qgqfqSlrlGdlTbalYqS/lxdFGuirPyLdeXpwvPV6l9bp6WXG0Xl9Pq/qirtICK+miZNKmHmNEF4ZVfakYWdeXMi7JN/JlhBF4PVbypC1JPxgAlIwUlkwJUZNqhFV5KlbVN6oLnqoraZVnZE+1pWKlvpQXRxvpqjwj33p5cb70eJXW6+plxdF6fT2t6ou6SguspIuSSZt6jBFdGFb1pWJkXV/KuCTfyJcRRuD1WMmTtiT9fwDpCm8qlzg+7wAAAABJRU5ErkJggg==)\r\n",
        "\r\n",
        "RIDGE linear regression\r\n",
        "\r\n",
        "\r\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZxX-o3bE4hm"
      },
      "source": [
        "# Ridge linear regression\n",
        "# Defining the get_coeff_ridge_normaleq function\n",
        "# Returning w values\n",
        "\n",
        "def get_coeff_ridge_normaleq(X_train, y_train, alpha):\n",
        "    # Getting the number of rows and columns of X_train\n",
        "    m, n = X_train.shape\n",
        "    # Splitting W into two parts a and b for easier calculation\n",
        "    a = np.linalg.pinv(np.dot(np.transpose(X_train), X_train) + alpha * np.identity(n)) #getting the appropriate identity matrix size\n",
        "    b = np.dot(np.transpose(X_train), y_train)\n",
        "    w = np.dot(a, b)\n",
        "\n",
        "    return w\n",
        "   \n",
        "#get_coeff_ridge_normaleq(x_2, y_2, 0.5)\n",
        "\n",
        "#m, n = (2,3)\n",
        "#I = np.identity(n)\n",
        "#print(n)\n",
        "#print(I)\n",
        "#c = np.arange(4).reshape((2,2))\n",
        "#print(c)\n",
        "#print(np.transpose(c))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDyCCwEeE4hm"
      },
      "source": [
        "# Simple linear regression\n",
        "# Defining the get_coeff_linear_normaleq function.\n",
        "# Returning w values\n",
        "\n",
        "def get_coeff_linear_normaleq(X_train, y_train):\n",
        "    a = np.linalg.pinv(np.dot(np.transpose(X_train), X_train))\n",
        "    b = np.dot(np.transpose(X_train), y_train)\n",
        "    w = np.dot(a, b)\n",
        "\n",
        "    return w\n",
        "\n",
        "#get_coeff_linear_normaleq(x_2, y_2)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha248AafE4hn"
      },
      "source": [
        "# Evaluating errors\n",
        "# Defining the evaluate_err_ridge function.\n",
        "# Returning the train_error and test_error values\n",
        "\n",
        "def evaluate_err(X_train, X_test, y_train, y_test, w): \n",
        "    #pred_train = prediction using w and X_train\n",
        "    pred_train = np.dot(X_train, w)\n",
        "    #pred_test = prediction using w and X_test\n",
        "    pred_test = np.dot(X_test, w)\n",
        "    \n",
        "    train_error = np.mean(np.square(y_train - pred_train))\n",
        "    test_error = np.mean(np.square(y_test - pred_test))\n",
        "    \n",
        "    return train_error, test_error"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQwFhIWME4hn"
      },
      "source": [
        "# Finish writting the k_fold_cross_validation function - used to estimate the skill of the model on new data\n",
        "# Returns the average training error and average test error from the k-fold cross validation\n",
        "# Sklearns K-Folds cross-validator: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
        "\n",
        "def k_fold_cross_validation(k, X, y, alpha):\n",
        "    kf = KFold(n_splits=k, random_state=21, shuffle=True)\n",
        "    total_E_val_test = 0\n",
        "    total_E_val_train = 0\n",
        "    # Creating empty arrays for errors so it's simple to find a mean value later on\n",
        "    all_train_errors = []\n",
        "    all_test_errors = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "        # Centering the data so we do not need the intercept term (we could have also chose w_0=average y value)\n",
        "        # Subtract y_train_mean from y_train and y_test\n",
        "        y_train_mean = np.mean(y_train)\n",
        "        y_train -= y_train_mean\n",
        "        y_test -= y_train_mean\n",
        "        \n",
        "        # Scaling the data matrix\n",
        "        scaler = sklearn.preprocessing.StandardScaler().fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Determining the training error and the testing error \n",
        "\n",
        "        # In case alpha is 0 - we will be using simple linear regression\n",
        "        if alpha == 0:\n",
        "            w = get_coeff_linear_normaleq(X_train, y_train)\n",
        "            total_E_val_train, total_E_val_test = evaluate_err(X_train, X_test, y_train, y_test, w)\n",
        "            print(\"\\n--- Train Error --- \", total_E_val_train, \" --- Test Error --- \", total_E_val_test)\n",
        "\n",
        "        # Else we have ridge linear regression and we are passing different values of alpha\n",
        "        else:\n",
        "            w = get_coeff_ridge_normaleq(X_train, y_train, alpha) \n",
        "            total_E_val_train, total_E_val_test = evaluate_err(X_train, X_test, y_train, y_test, w)\n",
        "            print(\"\\n--- Train Error --- \", total_E_val_train, \" --- Test Error --- \", total_E_val_test)\n",
        "        \n",
        "        # Appending the errors to the lists so we can easily find mean value \n",
        "        all_train_errors.append(total_E_val_train)\n",
        "        all_test_errors.append(total_E_val_test)\n",
        "\n",
        "    # Finding the mean\n",
        "    mean_train_error = np.mean(all_train_errors)\n",
        "    mean_test_error = np.mean(all_test_errors)\n",
        "    # Printing the mean errors\n",
        "    print(\"\\nThe average Train Error is: \", mean_train_error)\n",
        "    print(\"The average Test Error is: \", mean_test_error, \"\\n\")\n",
        "\n",
        "    return  total_E_val_test, total_E_val_train"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQZSu51yE4hp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5016c552-e15e-4b4f-c8af-36fefd418ef0"
      },
      "source": [
        "# Testing various polynomial regressions (requirement 6) asked in the question, and the various regularization alphas (requirement 4)\n",
        "\n",
        "# Number of k splits\n",
        "k = 10\n",
        "print(\"\\n--------------- Testing first degree polynomial ----------------------\")\n",
        "\n",
        "# Simple linear regression\n",
        "print(\"\\n-------------- Simple Linear Regression -----------------\")\n",
        "k_fold_cross_validation(k, X, y, 0)\n",
        "# Ridge linear regression\n",
        "print(\"\\n-------------- Ridge Linear Regression -----------------\")\n",
        "for i in np.logspace(1,7,num=13):\n",
        "    print(\"--------------- Alpha value: \", i, \" -----------------\")\n",
        "    k_fold_cross_validation(k, X, y, i)\n",
        "    \n",
        "print(\"\\n--------------- Testing second degree polynomial ---------------------\")\n",
        "# Simple linear regression\n",
        "print(\"\\n-------------- Simple Linear Regression -----------------\")\n",
        "k_fold_cross_validation(k, X_2, y_2, 0)\n",
        "# Ridge linear regression\n",
        "print(\"\\n-------------- Ridge Linear Regression -----------------\")\n",
        "for i in np.logspace(1,7,num=13):\n",
        "    print(\"--------------- Alpha value: \", i, \" -----------------\")\n",
        "    k_fold_cross_validation(k, X_2, y_2, i) \n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--------------- Testing first degree polynomial ----------------------\n",
            "\n",
            "-------------- Simple Linear Regression -----------------\n",
            "\n",
            "--- Train Error ---  20.24449673622922  --- Test Error ---  37.10404242136755\n",
            "\n",
            "--- Train Error ---  22.585288719515688  --- Test Error ---  17.124437638486523\n",
            "\n",
            "--- Train Error ---  21.210327793796587  --- Test Error ---  29.085058645356895\n",
            "\n",
            "--- Train Error ---  22.103993371741506  --- Test Error ---  20.750965145964653\n",
            "\n",
            "--- Train Error ---  22.725969159268512  --- Test Error ---  15.480509662951537\n",
            "\n",
            "--- Train Error ---  22.085862090246614  --- Test Error ---  21.168944735113563\n",
            "\n",
            "--- Train Error ---  23.2180545765112  --- Test Error ---  10.543450662554815\n",
            "\n",
            "--- Train Error ---  21.19189183114535  --- Test Error ---  29.64230462865989\n",
            "\n",
            "--- Train Error ---  22.360749008114812  --- Test Error ---  18.71020551186712\n",
            "\n",
            "--- Train Error ---  20.335202471941134  --- Test Error ---  36.750767001958714\n",
            "\n",
            "The average Train Error is:  21.806183575851062\n",
            "The average Test Error is:  23.636068605428125 \n",
            "\n",
            "\n",
            "-------------- Ridge Linear Regression -----------------\n",
            "--------------- Alpha value:  10.0  -----------------\n",
            "\n",
            "--- Train Error ---  20.332371865485477  --- Test Error ---  37.03173296825327\n",
            "\n",
            "--- Train Error ---  22.670819138887776  --- Test Error ---  17.226959155002064\n",
            "\n",
            "--- Train Error ---  21.306961450401797  --- Test Error ---  28.982526043416435\n",
            "\n",
            "--- Train Error ---  22.187785392234673  --- Test Error ---  21.102410934565267\n",
            "\n",
            "--- Train Error ---  22.810091247806852  --- Test Error ---  15.281190415948831\n",
            "\n",
            "--- Train Error ---  22.168378732592515  --- Test Error ---  21.004310097295413\n",
            "\n",
            "--- Train Error ---  23.31130434952373  --- Test Error ---  10.152412834364348\n",
            "\n",
            "--- Train Error ---  21.283496910214666  --- Test Error ---  30.046788415827418\n",
            "\n",
            "--- Train Error ---  22.440527553226364  --- Test Error ---  18.60019770649566\n",
            "\n",
            "--- Train Error ---  20.417274935328017  --- Test Error ---  37.45730144521862\n",
            "\n",
            "The average Train Error is:  21.892901157570186\n",
            "The average Test Error is:  23.688583001638733 \n",
            "\n",
            "--------------- Alpha value:  31.622776601683793  -----------------\n",
            "\n",
            "--- Train Error ---  20.73252941698906  --- Test Error ---  37.184130180855796\n",
            "\n",
            "--- Train Error ---  23.06589229117326  --- Test Error ---  17.637346530920045\n",
            "\n",
            "--- Train Error ---  21.72456953059305  --- Test Error ---  29.417531689507214\n",
            "\n",
            "--- Train Error ---  22.56667491064669  --- Test Error ---  21.85035879177289\n",
            "\n",
            "--- Train Error ---  23.19902584118404  --- Test Error ---  14.945833526622737\n",
            "\n",
            "--- Train Error ---  22.551990572382266  --- Test Error ---  20.675725303692673\n",
            "\n",
            "--- Train Error ---  23.728197617832276  --- Test Error ---  9.850271583673097\n",
            "\n",
            "--- Train Error ---  21.683110622944408  --- Test Error ---  31.39687404717654\n",
            "\n",
            "--- Train Error ---  22.816847151282065  --- Test Error ---  18.400939970077317\n",
            "\n",
            "--- Train Error ---  20.785602601947858  --- Test Error ---  38.81939134956315\n",
            "\n",
            "The average Train Error is:  22.2854440556975\n",
            "The average Test Error is:  24.017840297386147 \n",
            "\n",
            "--------------- Alpha value:  100.0  -----------------\n",
            "\n",
            "--- Train Error ---  22.19072962400002  --- Test Error ---  38.28857491115391\n",
            "\n",
            "--- Train Error ---  24.531587451368843  --- Test Error ---  19.410095756098542\n",
            "\n",
            "--- Train Error ---  23.17654829597393  --- Test Error ---  31.532614849677117\n",
            "\n",
            "--- Train Error ---  23.947047556372215  --- Test Error ---  23.649647982169565\n",
            "\n",
            "--- Train Error ---  24.67153395913837  --- Test Error ---  14.101371360229216\n",
            "\n",
            "--- Train Error ---  24.024996746410817  --- Test Error ---  19.999708902489175\n",
            "\n",
            "--- Train Error ---  25.239269025753  --- Test Error ---  9.825925445158482\n",
            "\n",
            "--- Train Error ---  23.077792572926427  --- Test Error ---  35.85061941653581\n",
            "\n",
            "--- Train Error ---  24.256885975878994  --- Test Error ---  18.137683791470433\n",
            "\n",
            "--- Train Error ---  22.138492640998177  --- Test Error ---  42.14228312196904\n",
            "\n",
            "The average Train Error is:  23.725488384882077\n",
            "The average Test Error is:  25.293852553695128 \n",
            "\n",
            "--------------- Alpha value:  316.22776601683796  -----------------\n",
            "\n",
            "--- Train Error ---  26.64227605272681  --- Test Error ---  42.21060519951712\n",
            "\n",
            "--- Train Error ---  28.971896636984237  --- Test Error ---  25.60813965300711\n",
            "\n",
            "--- Train Error ---  27.51065919542338  --- Test Error ---  37.66693712687709\n",
            "\n",
            "--- Train Error ---  28.27880324664088  --- Test Error ---  27.90727518693834\n",
            "\n",
            "--- Train Error ---  29.39092444939907  --- Test Error ---  13.51616938245827\n",
            "\n",
            "--- Train Error ---  28.681819374541007  --- Test Error ---  20.49791852864449\n",
            "\n",
            "--- Train Error ---  29.888964418965575  --- Test Error ---  11.316979445812484\n",
            "\n",
            "--- Train Error ---  27.16347345544813  --- Test Error ---  47.10097228901441\n",
            "\n",
            "--- Train Error ---  28.799424856652166  --- Test Error ---  18.907371562728308\n",
            "\n",
            "--- Train Error ---  26.337299298620053  --- Test Error ---  49.84059385397043\n",
            "\n",
            "The average Train Error is:  28.166554098540132\n",
            "The average Test Error is:  29.457296222896808 \n",
            "\n",
            "--------------- Alpha value:  1000.0  -----------------\n",
            "\n",
            "--- Train Error ---  37.06382515152888  --- Test Error ---  50.892907668699124\n",
            "\n",
            "--- Train Error ---  39.073161497435166  --- Test Error ---  39.61416392120371\n",
            "\n",
            "--- Train Error ---  37.54018138771036  --- Test Error ---  50.00311974558985\n",
            "\n",
            "--- Train Error ---  38.57793715838877  --- Test Error ---  38.124787546572364\n",
            "\n",
            "--- Train Error ---  40.50689850783098  --- Test Error ---  17.71757675309287\n",
            "\n",
            "--- Train Error ---  39.53331111413181  --- Test Error ---  26.252214006295777\n",
            "\n",
            "--- Train Error ---  40.743997842197004  --- Test Error ---  17.14739910665939\n",
            "\n",
            "--- Train Error ---  36.4425810924941  --- Test Error ---  66.34692845913209\n",
            "\n",
            "--- Train Error ---  39.595589923357586  --- Test Error ---  23.34701007565307\n",
            "\n",
            "--- Train Error ---  36.244003598361  --- Test Error ---  65.44882631108877\n",
            "\n",
            "The average Train Error is:  38.53214872734357\n",
            "The average Test Error is:  39.48949335939871 \n",
            "\n",
            "--------------- Alpha value:  3162.2776601683795  -----------------\n",
            "\n",
            "--- Train Error ---  52.78668909698568  --- Test Error ---  63.541382594800055\n",
            "\n",
            "--- Train Error ---  53.92387706294464  --- Test Error ---  59.70186610483453\n",
            "\n",
            "--- Train Error ---  52.67269442979364  --- Test Error ---  66.2928637375576\n",
            "\n",
            "--- Train Error ---  54.015650845218175  --- Test Error ---  53.96133626456336\n",
            "\n",
            "--- Train Error ---  56.71106289164363  --- Test Error ---  29.375144002453126\n",
            "\n",
            "--- Train Error ---  55.579116589731505  --- Test Error ---  38.33884350150105\n",
            "\n",
            "--- Train Error ---  56.79488120021589  --- Test Error ---  28.2219503732632\n",
            "\n",
            "--- Train Error ---  50.694325062760484  --- Test Error ---  87.09892033211463\n",
            "\n",
            "--- Train Error ---  55.85528792998622  --- Test Error ---  32.206887844332364\n",
            "\n",
            "--- Train Error ---  51.03667988626503  --- Test Error ---  87.73271602407509\n",
            "\n",
            "The average Train Error is:  54.00702649955449\n",
            "The average Test Error is:  54.6471910779495 \n",
            "\n",
            "--------------- Alpha value:  10000.0  -----------------\n",
            "\n",
            "--- Train Error ---  68.33991247916948  --- Test Error ---  76.75950235601374\n",
            "\n",
            "--- Train Error ---  68.46860274989152  --- Test Error ---  79.20711484631687\n",
            "\n",
            "--- Train Error ---  67.83357049040251  --- Test Error ---  81.59405655145183\n",
            "\n",
            "--- Train Error ---  69.2698171266462  --- Test Error ---  69.25822822219476\n",
            "\n",
            "--- Train Error ---  72.23562301924203  --- Test Error ---  43.25347811653402\n",
            "\n",
            "--- Train Error ---  71.18153921782165  --- Test Error ---  51.78274639250926\n",
            "\n",
            "--- Train Error ---  72.43610062453752  --- Test Error ---  40.47915640260524\n",
            "\n",
            "--- Train Error ---  65.46123358478398  --- Test Error ---  103.90895963367304\n",
            "\n",
            "--- Train Error ---  71.89606139726693  --- Test Error ---  42.37009770852073\n",
            "\n",
            "--- Train Error ---  65.47535644277019  --- Test Error ---  108.57183485863156\n",
            "\n",
            "The average Train Error is:  69.2597817132532\n",
            "The average Test Error is:  69.7185175088451 \n",
            "\n",
            "--------------- Alpha value:  31622.776601683792  -----------------\n",
            "\n",
            "--- Train Error ---  77.77343065624741  --- Test Error ---  85.18554113118276\n",
            "\n",
            "--- Train Error ---  77.29502268977876  --- Test Error ---  90.96012333122799\n",
            "\n",
            "--- Train Error ---  77.13046854615166  --- Test Error ---  90.85115328301686\n",
            "\n",
            "--- Train Error ---  78.56214133946034  --- Test Error ---  78.37702309538028\n",
            "\n",
            "--- Train Error ---  81.54189540827097  --- Test Error ---  52.10903172098447\n",
            "\n",
            "--- Train Error ---  80.58777359768655  --- Test Error ---  60.240049214345014\n",
            "\n",
            "--- Train Error ---  81.90141130613253  --- Test Error ---  48.23827714421457\n",
            "\n",
            "--- Train Error ---  74.67113277532297  --- Test Error ---  113.5750777022349\n",
            "\n",
            "--- Train Error ---  81.64993177862894  --- Test Error ---  49.01036771965267\n",
            "\n",
            "--- Train Error ---  74.19421626524682  --- Test Error ---  120.66956670127068\n",
            "\n",
            "The average Train Error is:  78.53074243629268\n",
            "The average Test Error is:  78.92162110435103 \n",
            "\n",
            "--------------- Alpha value:  100000.0  -----------------\n",
            "\n",
            "--- Train Error ---  81.70633937270566  --- Test Error ---  88.77457630228153\n",
            "\n",
            "--- Train Error ---  80.98068291390926  --- Test Error ---  95.84884257652095\n",
            "\n",
            "--- Train Error ---  81.02677627455243  --- Test Error ---  94.72476703002289\n",
            "\n",
            "--- Train Error ---  82.44759435253172  --- Test Error ---  82.15583090677215\n",
            "\n",
            "--- Train Error ---  85.41017190950602  --- Test Error ---  55.85253424363576\n",
            "\n",
            "--- Train Error ---  84.50406975014225  --- Test Error ---  63.804610148407335\n",
            "\n",
            "--- Train Error ---  85.85092430891592  --- Test Error ---  51.52061345132701\n",
            "\n",
            "--- Train Error ---  78.55318565642857  --- Test Error ---  117.56730716081438\n",
            "\n",
            "--- Train Error ---  85.72594799422427  --- Test Error ---  51.86122038454473\n",
            "\n",
            "--- Train Error ---  77.82680871622051  --- Test Error ---  125.61374069027228\n",
            "\n",
            "The average Train Error is:  82.40325012491367\n",
            "The average Test Error is:  82.7724042894599 \n",
            "\n",
            "--------------- Alpha value:  316227.7660168379  -----------------\n",
            "\n",
            "--- Train Error ---  83.07819437687645  --- Test Error ---  90.03588039324886\n",
            "\n",
            "--- Train Error ---  82.26726773944412  --- Test Error ---  97.55284806477452\n",
            "\n",
            "--- Train Error ---  82.3885117265508  --- Test Error ---  96.0784652929134\n",
            "\n",
            "--- Train Error ---  83.80452294701978  --- Test Error ---  83.47147939784632\n",
            "\n",
            "--- Train Error ---  86.7584407353893  --- Test Error ---  57.1636853091511\n",
            "\n",
            "--- Train Error ---  85.86973918887384  --- Test Error ---  65.05216727856157\n",
            "\n",
            "--- Train Error ---  87.2293616911557  --- Test Error ---  52.671027514985354\n",
            "\n",
            "--- Train Error ---  79.91240012579821  --- Test Error ---  118.95748587442908\n",
            "\n",
            "--- Train Error ---  87.14918942509178  --- Test Error ---  52.86574812628717\n",
            "\n",
            "--- Train Error ---  79.0938608171653  --- Test Error ---  127.32607532998054\n",
            "\n",
            "The average Train Error is:  83.75514887733652\n",
            "The average Test Error is:  84.11748625821778 \n",
            "\n",
            "--------------- Alpha value:  1000000.0  -----------------\n",
            "\n",
            "--- Train Error ---  83.52623932715655  --- Test Error ---  90.44882576649476\n",
            "\n",
            "--- Train Error ---  82.687577599394  --- Test Error ---  98.10924403355698\n",
            "\n",
            "--- Train Error ---  82.8335412322742  --- Test Error ---  96.52087812747307\n",
            "\n",
            "--- Train Error ---  84.24787591375822  --- Test Error ---  83.90091908887089\n",
            "\n",
            "--- Train Error ---  87.19868508627253  --- Test Error ---  57.592446883685234\n",
            "\n",
            "--- Train Error ---  86.31573169855912  --- Test Error ---  65.46004676432734\n",
            "\n",
            "--- Train Error ---  87.67965570140498  --- Test Error ---  53.04732725821425\n",
            "\n",
            "--- Train Error ---  80.35685934185184  --- Test Error ---  119.41133918130927\n",
            "\n",
            "--- Train Error ---  87.6141860133876  --- Test Error ---  53.194907431063704\n",
            "\n",
            "--- Train Error ---  79.50768157214367  --- Test Error ---  127.88400729767756\n",
            "\n",
            "The average Train Error is:  84.19680334862025\n",
            "The average Test Error is:  84.5569941832673 \n",
            "\n",
            "--------------- Alpha value:  3162277.6601683795  -----------------\n",
            "\n",
            "--- Train Error ---  83.66939562228968  --- Test Error ---  90.5808701103573\n",
            "\n",
            "--- Train Error ---  82.82188414453367  --- Test Error ---  98.28700694703217\n",
            "\n",
            "--- Train Error ---  82.97576386732602  --- Test Error ---  96.66226623119633\n",
            "\n",
            "--- Train Error ---  84.38955205749205  --- Test Error ---  84.03810586556202\n",
            "\n",
            "--- Train Error ---  87.3393395008288  --- Test Error ---  57.729496311220714\n",
            "\n",
            "--- Train Error ---  86.45822923862534  --- Test Error ---  65.5904130271955\n",
            "\n",
            "--- Train Error ---  87.82354124358369  --- Test Error ---  53.16761865417552\n",
            "\n",
            "--- Train Error ---  80.49892531628882  --- Test Error ---  119.5563358346813\n",
            "\n",
            "--- Train Error ---  87.76277625068485  --- Test Error ---  53.30018887947627\n",
            "\n",
            "--- Train Error ---  79.63990353173246  --- Test Error ---  128.06213977248953\n",
            "\n",
            "The average Train Error is:  84.33793107733854\n",
            "The average Test Error is:  84.69744416333867 \n",
            "\n",
            "--------------- Alpha value:  10000000.0  -----------------\n",
            "\n",
            "--- Train Error ---  83.7148144375105  --- Test Error ---  90.6227738206546\n",
            "\n",
            "--- Train Error ---  82.86449644010146  --- Test Error ---  98.343404011728\n",
            "\n",
            "--- Train Error ---  83.02088947200255  --- Test Error ---  96.70712724222066\n",
            "\n",
            "--- Train Error ---  84.434503191952  --- Test Error ---  84.08162825698344\n",
            "\n",
            "--- Train Error ---  87.38396361101215  --- Test Error ---  57.772983065351816\n",
            "\n",
            "--- Train Error ---  86.50343876342511  --- Test Error ---  65.63177833145929\n",
            "\n",
            "--- Train Error ---  87.86919251279852  --- Test Error ---  53.20578907913546\n",
            "\n",
            "--- Train Error ---  80.54400378095454  --- Test Error ---  119.60233705595765\n",
            "\n",
            "--- Train Error ---  87.80992087051035  --- Test Error ---  53.333602390800316\n",
            "\n",
            "--- Train Error ---  79.68185332513295  --- Test Error ---  128.11864187616018\n",
            "\n",
            "The average Train Error is:  84.38270764054002\n",
            "The average Test Error is:  84.74200651304514 \n",
            "\n",
            "\n",
            "--------------- Testing second degree polynomial ---------------------\n",
            "\n",
            "-------------- Simple Linear Regression -----------------\n",
            "\n",
            "--- Train Error ---  4.8928370854214025  --- Test Error ---  19.75007201368953\n",
            "\n",
            "--- Train Error ---  6.022435910900392  --- Test Error ---  18.438122343118327\n",
            "\n",
            "--- Train Error ---  6.0667140895395075  --- Test Error ---  8.60581463468607\n",
            "\n",
            "--- Train Error ---  6.1536873814124045  --- Test Error ---  7.241738749223657\n",
            "\n",
            "--- Train Error ---  6.035489015801274  --- Test Error ---  8.004499685682763\n",
            "\n",
            "--- Train Error ---  5.959727702482868  --- Test Error ---  9.02470881098913\n",
            "\n",
            "--- Train Error ---  5.968520674247682  --- Test Error ---  7.9991075470109445\n",
            "\n",
            "--- Train Error ---  5.8816913537965325  --- Test Error ---  10.426862510966902\n",
            "\n",
            "--- Train Error ---  5.593665396821355  --- Test Error ---  13.268520247871468\n",
            "\n",
            "--- Train Error ---  5.5134395497012445  --- Test Error ---  15.790235788298089\n",
            "\n",
            "The average Train Error is:  5.808820816012467\n",
            "The average Test Error is:  11.854968233153688 \n",
            "\n",
            "\n",
            "-------------- Ridge Linear Regression -----------------\n",
            "--------------- Alpha value:  10.0  -----------------\n",
            "\n",
            "--- Train Error ---  9.184003944313256  --- Test Error ---  21.36603281923307\n",
            "\n",
            "--- Train Error ---  10.419336824102963  --- Test Error ---  9.05140892498888\n",
            "\n",
            "--- Train Error ---  10.065858145588289  --- Test Error ---  14.243648234331534\n",
            "\n",
            "--- Train Error ---  10.572572153710949  --- Test Error ---  6.473584136683472\n",
            "\n",
            "--- Train Error ---  10.001477687615848  --- Test Error ---  16.94415886145362\n",
            "\n",
            "--- Train Error ---  10.229882942591889  --- Test Error ---  11.70101539209916\n",
            "\n",
            "--- Train Error ---  10.424354358197503  --- Test Error ---  7.712396926962891\n",
            "\n",
            "--- Train Error ---  10.164804210698712  --- Test Error ---  12.237831705289379\n",
            "\n",
            "--- Train Error ---  10.148865359287097  --- Test Error ---  10.188012918902736\n",
            "\n",
            "--- Train Error ---  9.27940311508234  --- Test Error ---  24.84329009141698\n",
            "\n",
            "The average Train Error is:  10.049055874118887\n",
            "The average Test Error is:  13.476138001136173 \n",
            "\n",
            "--------------- Alpha value:  31.622776601683793  -----------------\n",
            "\n",
            "--- Train Error ---  11.826524943000525  --- Test Error ---  24.895561351456188\n",
            "\n",
            "--- Train Error ---  13.134512285904934  --- Test Error ---  10.933941824726558\n",
            "\n",
            "--- Train Error ---  12.595118427161143  --- Test Error ---  17.89434321357308\n",
            "\n",
            "--- Train Error ---  13.390665395522918  --- Test Error ---  8.274140599936652\n",
            "\n",
            "--- Train Error ---  12.670002470538346  --- Test Error ---  17.654169757165967\n",
            "\n",
            "--- Train Error ---  12.851895395887183  --- Test Error ---  14.924828453067294\n",
            "\n",
            "--- Train Error ---  13.275544872181701  --- Test Error ---  8.350961330602155\n",
            "\n",
            "--- Train Error ---  12.845206377324542  --- Test Error ---  16.18861276807396\n",
            "\n",
            "--- Train Error ---  13.051344646295842  --- Test Error ---  11.453646377176865\n",
            "\n",
            "--- Train Error ---  11.876247876650707  --- Test Error ---  27.725814014733775\n",
            "\n",
            "The average Train Error is:  12.751706269046785\n",
            "The average Test Error is:  15.829601969051248 \n",
            "\n",
            "--------------- Alpha value:  100.0  -----------------\n",
            "\n",
            "--- Train Error ---  15.153254676951066  --- Test Error ---  29.515825026187656\n",
            "\n",
            "--- Train Error ---  16.6919360458689  --- Test Error ---  13.345757685530062\n",
            "\n",
            "--- Train Error ---  15.972959151381547  --- Test Error ---  21.858931836247134\n",
            "\n",
            "--- Train Error ---  17.004420416300523  --- Test Error ---  11.441003503870261\n",
            "\n",
            "--- Train Error ---  16.269833482327023  --- Test Error ---  17.750496011742317\n",
            "\n",
            "--- Train Error ---  16.24371590788592  --- Test Error ---  17.784272477564922\n",
            "\n",
            "--- Train Error ---  16.99953818113779  --- Test Error ---  9.300458432604634\n",
            "\n",
            "--- Train Error ---  16.185995342604013  --- Test Error ---  22.091196966909507\n",
            "\n",
            "--- Train Error ---  16.64327397541568  --- Test Error ---  14.219346472073916\n",
            "\n",
            "--- Train Error ---  15.061978752235547  --- Test Error ---  32.49289973736879\n",
            "\n",
            "The average Train Error is:  16.2226905932108\n",
            "The average Test Error is:  18.98001881500992 \n",
            "\n",
            "--------------- Alpha value:  316.22776601683796  -----------------\n",
            "\n",
            "--- Train Error ---  18.46537949051038  --- Test Error ---  34.15877045071633\n",
            "\n",
            "--- Train Error ---  20.310087239399405  --- Test Error ---  16.3266942994647\n",
            "\n",
            "--- Train Error ---  19.404899021825457  --- Test Error ---  25.992433172630385\n",
            "\n",
            "--- Train Error ---  20.48385795973346  --- Test Error ---  15.593794133770398\n",
            "\n",
            "--- Train Error ---  19.98650972126876  --- Test Error ---  16.79800191965002\n",
            "\n",
            "--- Train Error ---  19.782417498397376  --- Test Error ---  19.422728270876934\n",
            "\n",
            "--- Train Error ---  20.74231752031886  --- Test Error ---  9.988282283666194\n",
            "\n",
            "--- Train Error ---  19.444137245125756  --- Test Error ---  28.93040689802431\n",
            "\n",
            "--- Train Error ---  20.166749347554735  --- Test Error ---  16.187798743897638\n",
            "\n",
            "--- Train Error ---  18.216181419964293  --- Test Error ---  37.2880129079304\n",
            "\n",
            "The average Train Error is:  19.700253646409852\n",
            "The average Test Error is:  22.06869230806273 \n",
            "\n",
            "--------------- Alpha value:  1000.0  -----------------\n",
            "\n",
            "--- Train Error ---  22.882643254924705  --- Test Error ---  39.743175547794465\n",
            "\n",
            "--- Train Error ---  24.969802329462322  --- Test Error ---  21.788270766782084\n",
            "\n",
            "--- Train Error ---  23.885805210729355  --- Test Error ---  31.904954041887063\n",
            "\n",
            "--- Train Error ---  24.955391300899894  --- Test Error ---  20.907191045798147\n",
            "\n",
            "--- Train Error ---  24.93097060660505  --- Test Error ---  15.467119055402689\n",
            "\n",
            "--- Train Error ---  24.501483089978443  --- Test Error ---  21.068016686938595\n",
            "\n",
            "--- Train Error ---  25.609088068786843  --- Test Error ---  10.958133775221256\n",
            "\n",
            "--- Train Error ---  23.70435256582436  --- Test Error ---  39.08943176399032\n",
            "\n",
            "--- Train Error ---  24.83424903832137  --- Test Error ---  17.331346087196106\n",
            "\n",
            "--- Train Error ---  22.600794365556563  --- Test Error ---  43.92711717303762\n",
            "\n",
            "The average Train Error is:  24.28745798310889\n",
            "The average Test Error is:  26.218475594404833 \n",
            "\n",
            "--------------- Alpha value:  3162.2776601683795  -----------------\n",
            "\n",
            "--- Train Error ---  31.484281852478052  --- Test Error ---  48.42333262298382\n",
            "\n",
            "--- Train Error ---  33.613069069637795  --- Test Error ---  33.18285681936483\n",
            "\n",
            "--- Train Error ---  32.462280247924625  --- Test Error ---  42.73520936033419\n",
            "\n",
            "--- Train Error ---  33.682655262335025  --- Test Error ---  30.377567154041202\n",
            "\n",
            "--- Train Error ---  34.410845398829956  --- Test Error ---  16.77965127165632\n",
            "\n",
            "--- Train Error ---  33.597831542595955  --- Test Error ---  25.26595000684985\n",
            "\n",
            "--- Train Error ---  34.86427968030611  --- Test Error ---  14.549133677771731\n",
            "\n",
            "--- Train Error ---  31.739693063747428  --- Test Error ---  56.69375854770692\n",
            "\n",
            "--- Train Error ---  33.92019195012399  --- Test Error ---  20.55328934839073\n",
            "\n",
            "--- Train Error ---  31.091555130526327  --- Test Error ---  57.24191137890212\n",
            "\n",
            "The average Train Error is:  33.08666831985052\n",
            "The average Test Error is:  34.580266018800174 \n",
            "\n",
            "--------------- Alpha value:  10000.0  -----------------\n",
            "\n",
            "--- Train Error ---  45.1544776943196  --- Test Error ---  59.606286056337396\n",
            "\n",
            "--- Train Error ---  46.85652321556199  --- Test Error ---  50.06707211995043\n",
            "\n",
            "--- Train Error ---  45.7280611881626  --- Test Error ---  58.35214740463396\n",
            "\n",
            "--- Train Error ---  47.24318057931446  --- Test Error ---  45.23979797383872\n",
            "\n",
            "--- Train Error ---  49.03679339985966  --- Test Error ---  24.395254357267856\n",
            "\n",
            "--- Train Error ---  47.8659018019809  --- Test Error ---  33.91715651247429\n",
            "\n",
            "--- Train Error ---  49.224409451395395  --- Test Error ---  22.62995189297411\n",
            "\n",
            "--- Train Error ---  44.06615876900944  --- Test Error ---  78.21779106018742\n",
            "\n",
            "--- Train Error ---  48.25110025536314  --- Test Error ---  28.001357194776936\n",
            "\n",
            "--- Train Error ---  44.19338723917364  --- Test Error ---  77.46839130323379\n",
            "\n",
            "The average Train Error is:  46.761999359414084\n",
            "The average Test Error is:  47.78952058756749 \n",
            "\n",
            "--------------- Alpha value:  31622.776601683792  -----------------\n",
            "\n",
            "--- Train Error ---  60.73830141142522  --- Test Error ---  71.5081009519143\n",
            "\n",
            "--- Train Error ---  61.50068452656786  --- Test Error ---  69.07939715240623\n",
            "\n",
            "--- Train Error ---  60.63900598040621  --- Test Error ---  74.36937738364686\n",
            "\n",
            "--- Train Error ---  62.282097921510115  --- Test Error ---  61.51249792035427\n",
            "\n",
            "--- Train Error ---  64.86226327134689  --- Test Error ---  36.90383462817694\n",
            "\n",
            "--- Train Error ---  63.69938944032452  --- Test Error ---  45.808511284329136\n",
            "\n",
            "--- Train Error ---  65.04916355146622  --- Test Error ---  34.03820047022299\n",
            "\n",
            "--- Train Error ---  58.34800870855939  --- Test Error ---  96.46693273396339\n",
            "\n",
            "--- Train Error ---  64.2866865021569  --- Test Error ---  37.658821174768754\n",
            "\n",
            "--- Train Error ---  58.684417854597214  --- Test Error ---  99.11721443465065\n",
            "\n",
            "The average Train Error is:  62.009001916836056\n",
            "The average Test Error is:  62.646288813443356 \n",
            "\n",
            "--------------- Alpha value:  100000.0  -----------------\n",
            "\n",
            "--- Train Error ---  73.35850258343847  --- Test Error ---  81.74996728488426\n",
            "\n",
            "--- Train Error ---  73.233069263939  --- Test Error ---  84.99517991302426\n",
            "\n",
            "--- Train Error ---  72.85691144843635  --- Test Error ---  86.69283034108174\n",
            "\n",
            "--- Train Error ---  74.4239290805064  --- Test Error ---  74.0507917955951\n",
            "\n",
            "--- Train Error ---  77.28827211111106  --- Test Error ---  48.21400251514227\n",
            "\n",
            "--- Train Error ---  76.27054427191554  --- Test Error ---  56.49300052407892\n",
            "\n",
            "--- Train Error ---  77.61466259411122  --- Test Error ---  44.35873275549645\n",
            "\n",
            "--- Train Error ---  70.3977710805932  --- Test Error ---  109.32013347877499\n",
            "\n",
            "--- Train Error ---  77.19357627594871  --- Test Error ---  46.08787994954679\n",
            "\n",
            "--- Train Error ---  70.23865074867429  --- Test Error ---  115.41699750655873\n",
            "\n",
            "The average Train Error is:  74.28758894586744\n",
            "The average Test Error is:  74.73795160641833 \n",
            "\n",
            "--------------- Alpha value:  316227.7660168379  -----------------\n",
            "\n",
            "--- Train Error ---  79.93251181432335  --- Test Error ---  87.33978527906731\n",
            "\n",
            "--- Train Error ---  79.34436933913858  --- Test Error ---  93.44370470844221\n",
            "\n",
            "--- Train Error ---  79.29497368078842  --- Test Error ---  93.0513596429892\n",
            "\n",
            "--- Train Error ---  80.77297681856594  --- Test Error ---  80.4372017304219\n",
            "\n",
            "--- Train Error ---  83.70281586904474  --- Test Error ---  54.265375246425826\n",
            "\n",
            "--- Train Error ---  82.77195053805042  --- Test Error ---  62.26706242185782\n",
            "\n",
            "--- Train Error ---  84.12672164843191  --- Test Error ---  49.946364976879416\n",
            "\n",
            "--- Train Error ---  76.81630644952666  --- Test Error ---  115.85157500325631\n",
            "\n",
            "--- Train Error ---  83.92826875979223  --- Test Error ---  50.657692176246286\n",
            "\n",
            "--- Train Error ---  76.23461860601157  --- Test Error ---  123.53974070953272\n",
            "\n",
            "The average Train Error is:  80.69255135236737\n",
            "The average Test Error is:  81.0799861895119 \n",
            "\n",
            "--------------- Alpha value:  1000000.0  -----------------\n",
            "\n",
            "--- Train Error ---  82.46933375567755  --- Test Error ---  89.53731284631634\n",
            "\n",
            "--- Train Error ---  81.70502786718494  --- Test Error ---  96.72643566961895\n",
            "\n",
            "--- Train Error ---  81.79235057488364  --- Test Error ---  95.50345374037786\n",
            "\n",
            "--- Train Error ---  83.22834470565  --- Test Error ---  82.88355961381042\n",
            "\n",
            "--- Train Error ---  86.17248631698668  --- Test Error ---  56.61665123417362\n",
            "\n",
            "--- Train Error ---  85.27540550270726  --- Test Error ---  64.52107475757752\n",
            "\n",
            "--- Train Error ---  86.63722177814694  --- Test Error ---  52.12906388709221\n",
            "\n",
            "--- Train Error ---  79.31398984163106  --- Test Error ---  118.36727910297343\n",
            "\n",
            "--- Train Error ---  86.5312396266497  --- Test Error ---  52.449223805800564\n",
            "\n",
            "--- Train Error ---  78.54695700832549  --- Test Error ---  126.6183688527812\n",
            "\n",
            "The average Train Error is:  83.16723569778432\n",
            "The average Test Error is:  83.53524235105222 \n",
            "\n",
            "--------------- Alpha value:  3162277.6601683795  -----------------\n",
            "\n",
            "--- Train Error ---  83.32850596648484  --- Test Error ---  90.28628140861245\n",
            "\n",
            "--- Train Error ---  82.50492099061314  --- Test Error ---  97.84077280548918\n",
            "\n",
            "--- Train Error ---  82.63975047420413  --- Test Error ---  96.33406223804197\n",
            "\n",
            "--- Train Error ---  84.06061314654586  --- Test Error ---  83.71018642415733\n",
            "\n",
            "--- Train Error ---  87.00839674106238  --- Test Error ---  57.41456707598592\n",
            "\n",
            "--- Train Error ---  86.12273569572301  --- Test Error ---  65.28723201903756\n",
            "\n",
            "--- Train Error ---  87.48731642797279  --- Test Error ---  52.87115666677445\n",
            "\n",
            "--- Train Error ---  80.16228821243179  --- Test Error ---  119.21951026170494\n",
            "\n",
            "--- Train Error ---  87.41340377554518  --- Test Error ---  53.05927806591901\n",
            "\n",
            "--- Train Error ---  79.3300265790442  --- Test Error ---  127.65461094468283\n",
            "\n",
            "The average Train Error is:  84.00579580096272\n",
            "The average Test Error is:  84.36776579104057 \n",
            "\n",
            "--------------- Alpha value:  10000000.0  -----------------\n",
            "\n",
            "--- Train Error ---  83.60633365690595  --- Test Error ---  90.52896709329794\n",
            "\n",
            "--- Train Error ---  82.76362394917132  --- Test Error ---  98.20137636874095\n",
            "\n",
            "--- Train Error ---  82.91394082236924  --- Test Error ---  96.60267812994606\n",
            "\n",
            "--- Train Error ---  84.3298148814059  --- Test Error ---  83.9772965966175\n",
            "\n",
            "--- Train Error ---  87.278652430089  --- Test Error ---  57.67274358999013\n",
            "\n",
            "--- Train Error ---  86.39668004015799  --- Test Error ---  65.53526435825897\n",
            "\n",
            "--- Train Error ---  87.76219580781162  --- Test Error ---  53.11141724968923\n",
            "\n",
            "--- Train Error ---  80.4368484256407  --- Test Error ---  119.49514075313289\n",
            "\n",
            "--- Train Error ---  87.69873198607495  --- Test Error ---  53.25689690493537\n",
            "\n",
            "--- Train Error ---  79.58324064810935  --- Test Error ---  127.9890241622965\n",
            "\n",
            "The average Train Error is:  84.2770062647736\n",
            "The average Test Error is:  84.63708052069055 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9ifYd6itfSu"
      },
      "source": [
        "**Conclusion:**\r\n",
        "\r\n",
        "If I was given a choice of predicting future housing prices using one of the models, either simple linear or ridge linear regression I would choose the simple one, since when considering polynomial data (X_2) we can easily conclude that testing and training errors are the smallest (5 and 11) which makes it a better model.\r\n",
        "Moreover, as alpha valu is increasing, both errors are increasing in ridge linear regression.\r\n"
      ]
    }
  ]
}